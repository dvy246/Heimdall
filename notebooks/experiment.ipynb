{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdb7352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyyadav/miniforge3/envs/newenv/lib/python3.10/site-packages/pandas_ta/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langsmith import traceable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import Annotated,TypedDict,Literal,Dict,List,Any,Optional\n",
    "from bs4 import BeautifulSoup\n",
    "import requests # Added import\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage,BaseMessage\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import create_react_agent,tools_condition,ToolNode\n",
    "from finnhub import Client\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from pathlib import Path\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "import sys\n",
    "import finnhub\n",
    "import os\n",
    "from langchain.tools import tool\n",
    "from typing import Dict, Any,List,Optional,Literal\n",
    "from pydantic import BaseModel,Field\n",
    "import time \n",
    "import shutil\n",
    "from langgraph_supervisor import create_supervisor,create_handoff_tool\n",
    "from langgraph_swarm import create_swarm,create_handoff_tool\n",
    "from datetime import datetime,timedelta\n",
    "from sec_api import QueryApi\n",
    "import requests\n",
    "from sec_edgar_api import EdgarClient\n",
    "import json\n",
    "import pandas_ta as ta\n",
    "import os\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import sqlite3\n",
    "import logging\n",
    "import regex as re\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67f67545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as your ONLY state definition\n",
    "class HeimdallState(TypedDict):\n",
    "    ticker: str\n",
    "    mission_plan: Optional[str]\n",
    "    # This will store the final reports from each manager\n",
    "    financial_report: Optional[str]\n",
    "    news_report: Optional[str]\n",
    "    technical_report: Optional[str]\n",
    "    # The final, synthesized report\n",
    "    research_report:Optional[str]\n",
    "    risk_report:Optional[str]\n",
    "    final_report: Optional[str]\n",
    "    validation_report:Optional[str]\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "11f83d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGoogleGenerativeAI(api_key=os.getenv('google'),model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a82f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sentiment(BaseModel):\n",
    "    sentiment:Literal['positive','negative','neutral']=Field(...,description=\"you need to classify the sentiment of the message based on the analysis\")\n",
    "    reason:str =Field(...,description=\"you need to give the reason for the sentiment classification\")\n",
    "    overall_factors:Dict[str,str]=Field(...,description=\"Factors influencing the sentiment in which the key is sentiment and reason is the value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d894443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class reason_setiment(BaseModel):\n",
    "    overall_sentiment:Literal['positive','negative','neutral']=Field(...,description=\"you need to classify the sentiment of the message based on the analysis\")\n",
    "    analysis: Annotated[List, Field(min_items=1, description=\"List of bullet points explaining the sentiment classification.\")] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b77cda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_wstr_output=model.with_structured_output(reason_setiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db5da4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChatGroq.bind_tools of ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x3177ff670>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x3177fe110>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eed832fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_structure=model.with_structured_output(Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b896b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Google Gemini model\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    api_key=os.getenv(\"google\"),\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")\n",
    "\n",
    "# Tool to search the web\n",
    "@tool(description=\"Search the web for ticker symbols\")\n",
    "def search_web(query: str):\n",
    "    \"\"\"Searches the web for the given query and returns the top results\"\"\"\n",
    "    tavily = TavilySearchResults(max_results=20, api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    return tavily.invoke(query)\n",
    "\n",
    "# Schema for ticker\n",
    "class TICKER(BaseModel):\n",
    "    ticker: str = Field(..., description=\"The stock ticker symbol of the company\")\n",
    "\n",
    "# Pre-processing agent\n",
    "pre_processing_agent = create_react_agent(\n",
    "    model=model,\n",
    "    response_format=TICKER,\n",
    "    tools=[search_web],\n",
    "    name=\"pre_processing_agent\",\n",
    "    prompt=\"\"\"\n",
    "You are an assistant that extracts stock ticker symbols for given company names.\n",
    "\n",
    "Steps:\n",
    "1. Always try to find the ticker symbol using the `search_web` tool.\n",
    "2. Parse the results and extract only the ticker symbol (e.g., MSFT for Microsoft).\n",
    "3. Return only the ticker symbol, following the schema.\n",
    "\n",
    "Return in this exact JSON schema:\n",
    "{\"ticker\": \"<TICKER_SYMBOL>\"}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Example run\n",
    "result = pre_processing_agent.invoke({\n",
    "        'messages': [HumanMessage(content=\"apple\")]\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b415e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"ticker\": \"AAPL\"}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a23438",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_and_validate_ticker(company_name:str):\n",
    "    '''This function takes a company name and returns the ticker symbol and also validates it'''\n",
    "    print(f\"--- TICKER TOOL: Finding ticker for {company_name} ---\")\n",
    "    try:\n",
    "        # We ask a targeted question to get the ticker symbol\n",
    "        search_query = f\"What is the stock ticker for the company '{company_name}'?\"\n",
    "        tcker_model.invoke(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMPORTANT: The SEC API requires you to set a User-Agent.\n",
    "# Replace 'Your Name' and 'your.email@example.com' with your actual info.\n",
    "os.environ['EDGAR_USER_AGENT'] = 'Divy yadavdipu296@gmail.com'\n",
    "\n",
    "import aiohttp\n",
    "@tool(description='gets the latest 10k fillings')\n",
    "async def get_latest_10k_filing(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Asynchronously fetches the full text of the most recent 10-K filing for a given company ticker using sec_api.QueryApi.\n",
    "\n",
    "    Args:\n",
    "        ticker: The company's stock ticker (e.g., \"TSLA\").\n",
    "\n",
    "    Returns:\n",
    "        The plain text content of the 10-K filing's primary document.\n",
    "        Returns an error message if the filing cannot be fetched.\n",
    "    \"\"\"\n",
    "    print(f\"---  SEC TOOL: Fetching latest 10-K for {ticker} ---\")\n",
    "    try:\n",
    "        # Initialize QueryApi with your SEC API key\n",
    "        query_api = QueryApi(api_key=os.getenv('SEC_API_KEY')) # Assumes SEC_API_KEY in .env\n",
    "\n",
    "        # Query for the latest 10-K filing for the ticker\n",
    "        query = {\n",
    "            \"query\": {\"query_string\": {\"query\": f'ticker:{ticker} AND formType:\"10-K\"'}},\n",
    "            \"from\": 0,\n",
    "            \"size\": 1,\n",
    "            \"sort\": [{\"filedAt\": {\"order\": \"desc\"}}],\n",
    "        }\n",
    "        response = query_api.get_filings(query=query)\n",
    "        \n",
    "        if not response or not response.get(\"filings\"):\n",
    "            return f\"Error: No 10-K filings found for ticker {ticker}.\"\n",
    "\n",
    "        # Get the URL of the primary document from the latest filing\n",
    "        filing_url = response[\"filings\"][0].get(\"linkToHtml\")\n",
    "        \n",
    "        if not filing_url:\n",
    "            return f\"Error: Could not find a filing URL for {ticker}.\"\n",
    "\n",
    "        # Fetch the content of the filing URL asynchronously using aiohttp\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(filing_url, headers={'User-Agent': os.getenv('EDGAR_USER_AGENT')}) as resp:\n",
    "                filing_html = await resp.text()\n",
    "\n",
    "        # Use BeautifulSoup to parse the HTML and extract all text\n",
    "        soup = BeautifulSoup(filing_html, 'html.parser')\n",
    "        plain_text = soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "        print(f\"--- SEC TOOL: Successfully fetched and parsed 10-K for {ticker}. ---\")\n",
    "        return plain_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while fetching the SEC data: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"Searches the web for the the ticker and gives the result sentiment with analysis\")\n",
    "async def analyze_news_sentiment(ticker: str, days_back: int = 30) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyzes recent news sentiment for a given company ticker over a specified period.\n",
    "\n",
    "    Args:\n",
    "        ticker: The company's stock ticker (e.g., \"TSLA\").\n",
    "        days_back: Number of days to look back for news articles (default: 30).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing news sentiment analysis.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "        search_query = f\"{ticker} company news from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} of its performances and changes\"\n",
    "        # If search_web is async, await it; otherwise, call directly\n",
    "        if hasattr(search_web, \"__call__\") and getattr(search_web, \"__code__\", None) and \"async\" in str(type(search_web)):\n",
    "            news_result = await search_web(search_query)\n",
    "        else:\n",
    "            news_result = search_web(search_query)\n",
    "        if not news_result:\n",
    "            return {'error': f\" no articles found for the ticker {ticker} for the specific period\"}\n",
    "        news_text = ''\n",
    "        for i, result in enumerate(news_result[:10], 1):\n",
    "            news_text += f\"Article {i}: {result.get('title', 'No title')}\\n\"\n",
    "            news_text += f\"Content: {result.get('content', 'No content')[:200]}...\\n\\n\"\n",
    "    except Exception as e:\n",
    "        raise {'error': f\"An error occurred while fetching news articles: {e}\"}\n",
    "    # If model_with_structure.invoke is async, await it; otherwise, call directly\n",
    "    if hasattr(model_with_structure.invoke, \"__call__\") and getattr(model_with_structure.invoke, \"__code__\", None) and \"async\" in str(type(model_with_structure.invoke)):\n",
    "        sentiment_result = await model_with_structure.invoke(news_text)\n",
    "    else:\n",
    "        sentiment_result = model_with_structure.invoke(news_text)\n",
    "    prompt = f\"based on the {sentiment_result} provide a summary of the news sentiment with detailed reasons from the news text\"\n",
    "    # If model2_wstr_output.invoke is async, await it; otherwise, call directly\n",
    "    if hasattr(model2_wstr_output.invoke, \"__call__\") and getattr(model2_wstr_output.invoke, \"__code__\", None) and \"async\" in str(type(model2_wstr_output.invoke)):\n",
    "        final_sentiment_with_reason = await model2_wstr_output.invoke(prompt)\n",
    "    else:\n",
    "        final_sentiment_with_reason = model2_wstr_output.invoke(prompt)\n",
    "    return final_sentiment_with_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c054cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"gets the info of the particular companys overall functions\")\n",
    "async def company_overview(ticker:str):\n",
    "    '''gets the info of the particular companys overall functions with all the metrics of the company'''\n",
    "    api=os.getenv('Alpha_Vantage_Stock_API')\n",
    "    if not api:\n",
    "        return {'API KEY IS MISSING'}\n",
    "    try:\n",
    "        url=f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={ticker}&apikey={api}'\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                response.raise_for_status()\n",
    "                data=await response.json()\n",
    "        if \"Note\" in data or not data:\n",
    "                return {\"error\": f\"Could not fetch data for {ticker}. The API limit may be reached or the ticker is invalid.\"}\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return {'error':f\"An error occurred while fetching the data: {e}\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {'error':f\"An error occurred while fetching the data: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e505996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(description='gets the insider infor of the company')\n",
    "async def get_insider_info(ticker: str):\n",
    "    ''' returns the latest and historical insider transactions made by key stakeholders (e.g., founders, executives, board members, etc.) of a specific company.'''\n",
    "\n",
    "    api = os.getenv('Alpha_Vantage_Stock_API')\n",
    "    if not api:\n",
    "        return {'API KEY IS MISSING'}\n",
    "    url = f'https://www.alphavantage.co/query?function=INSIDER_TRANSACTIONS&symbol={ticker}&apikey={api}'\n",
    "    try:\n",
    "        import aiohttp\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "        if \"Note\" in data or not data:\n",
    "            return {\"error\": f\"Could not fetch data for {ticker}. The API limit may be reached or the ticker is invalid.\"}\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return {'error': f\"An error occurred while fetching the data: {e}\"}\n",
    "\n",
    "        \n",
    "@tool(description='does advanced analytics details of the company')\n",
    "async def advaced_analyst(\n",
    "    ticker: list[str],\n",
    "    interval: str,\n",
    "    window_size: int,\n",
    "    calculations: List[str],\n",
    "    range_str: str,\n",
    "    ohlc: Optional[str] = \"close\"\n",
    "):\n",
    "    ''' This endpoint returns a rich set of advanced analytics metrics (e.g., total return, variance, auto-correlation, etc.) for a given time series over sliding time windows. For example, we can calculate a moving variance over 5 years with a window of 100 points to see how the variance changes over time.'''\n",
    "    api = os.getenv('Alpha_Vantage_Stock_API')\n",
    "    if not api:\n",
    "        return {\"error\": \"Alpha Vantage API key not found.\"}\n",
    "\n",
    "    base_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"ANALYTICS_SLIDING_WINDOW\",\n",
    "        'SYMBOLS': ticker,\n",
    "        \"RANGE\": '6month',\n",
    "        \"INTERVAL\": interval,\n",
    "        \"WINDOW_SIZE\": window_size,\n",
    "        \"CALCULATIONS\": \",\".join(calculations),\n",
    "        \"OHLC\": ohlc,\n",
    "        \"apikey\": api\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        import aiohttp\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(base_url, params=params) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "\n",
    "        if \"Note\" in data or not data:\n",
    "            return {\"error\": \"Could not fetch data. API limit may be reached or parameters are invalid.\"}\n",
    "\n",
    "        return data.get(\"payload\", {\"error\": \"No payload found.\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {e}\"}\n",
    "        \n",
    "@tool(description=\"Fetches the current market status for a given exchange using the Finnhub API.\")\n",
    "def get_market_status(exchange: str) -> str:\n",
    "    ''' Fetches the current market status for a given exchange using the Finnhub API.'''\n",
    "    try:\n",
    "        finnhub_client = Client(api_key=os.getenv(\"FINNHUB_API_KEY\"))\n",
    "        get_market_status=finnhub_client.market_status(exchange='US')\n",
    "        return get_market_status\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {e}\"}\n",
    "\n",
    "@tool(description=\"Fetches insider sentiment data for a given stock ticker within a specified date range.\")\n",
    "async def get_insiders_sentiment(ticker: str) -> Dict[str, Any]:\n",
    "    '''Fetches insider sentiment data for a given stock ticker within a specified date range.'''\n",
    "    try:\n",
    "        import aiohttp\n",
    "\n",
    "        api_key = os.getenv(\"FINNHUB_API_KEY\")\n",
    "        if not api_key:\n",
    "            return {\"error\": \"FINNHUB_API_KEY not found in environment variables.\"}\n",
    "\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        start_date = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')\n",
    "\n",
    "        url = f\"https://finnhub.io/api/v1/stock/insider-sentiment\"\n",
    "        params = {\n",
    "            \"symbol\": ticker,\n",
    "            \"from\": start_date,\n",
    "            \"to\": end_date,\n",
    "            \"token\": api_key\n",
    "        }\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                response.raise_for_status()\n",
    "                sentiment_data = await response.json()\n",
    "\n",
    "        if not sentiment_data or 'data' not in sentiment_data:\n",
    "            return {\"message\": f\"No insider sentiment data found for {ticker} in the last 90 days.\"}\n",
    "        total_mspr = sum(item.get('mspr', 0) for item in sentiment_data['data'])\n",
    "        sentiment_score = \"Positive\" if total_mspr > 0 else \"Negative\" if total_mspr < 0 else \"Neutral\"\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"monthly_sentiment_score_mspr\": total_mspr,\n",
    "            \"overall_sentiment\": sentiment_score\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {e}\"} \n",
    "\n",
    "@tool(description=\"Use this tool to get the current date.\")\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Returns the current date in YYYY-MM-DD format.\"\"\"\n",
    "    return datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "@tool(description=\"\"\"\n",
    "    Use this tool to get key technical indicators (RSI, 50-day SMA, 200-day SMA) \n",
    "    for a given stock ticker. The input MUST be a single company stock ticker.\n",
    "    For example: 'AAPL' or 'TSLA'.\n",
    "\"\"\")\n",
    "def get_technichal_analysis(ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fetches historical stock data and calculates key technical indicators.\n",
    "        Returns a dictionary with the current price and indicators, or an error message.\n",
    "        \"\"\"\n",
    "        print(f\"--- TECHNICAL TOOL: Performing full analysis for {ticker} ---\")\n",
    "        try:\n",
    "            stock=yf.Ticker(ticker)\n",
    "            hist = stock.history(period=\"1y\")\n",
    "            \n",
    "            if hist.empty:\n",
    "                return f\"Error: No historical data found for ticker {ticker}.\"\n",
    "            \n",
    "            hist.columns=[col.capitalize() for col in hist.columns]\n",
    "            \n",
    "            #calculating metrics\n",
    "            hist.ta.rsi(append=True)\n",
    "            hist.ta.sma(length=50, append=True)\n",
    "            hist.ta.sma(length=200, append=True)\n",
    "\n",
    "            if 'RSI_14' not in hist.columns or 'SMA_50' not in hist.columns or 'SMA_200' not in hist.columns:\n",
    "                      return {\"error\": f\"Could not calculate all technical indicators for {ticker}. Not enough data.\"}\n",
    "                      \n",
    "            latest_indicators = {\n",
    "            \"current_price\": hist['Close'].iloc[-1],\n",
    "            \"rsi\": hist['RSI_14'].iloc[-1],\n",
    "            \"sma_50\": hist['SMA_50'].iloc[-1],\n",
    "            \"sma_200\": hist['SMA_200'].iloc[-1]\n",
    "        }\n",
    "\n",
    "            for key,value in latest_indicators.items():\n",
    "                if pd.isna(value):\n",
    "                    return {\"error\": f\"Could not calculate {key} for {ticker}. Not enough data.\"}\n",
    "            return latest_indicators\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while fetching the technical analysis: {e}\"\n",
    "\n",
    "@tool(description='gives back the income statement of the company')\n",
    "async def get_income_statements(ticker: str,period:Literal\n",
    "['annual','quarter']) -> Dict:\n",
    "    \"\"\"\n",
    "    Fetches the income statement of the specified company ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol of the company.\n",
    "        period (str): The period for the income statement, either 'annual' or 'quarter'.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the income statement data of the company,\n",
    "              or an error message if the API call fails or the API key is missing.\n",
    "\n",
    "    Description:\n",
    "        This tool queries the Financial Modeling Prep API to retrieve the income statement\n",
    "        for the given ticker symbol and period. It requires the 'FPREP' environment variable\n",
    "        to be set with a valid API key.\n",
    "    \"\"\"\n",
    "    api = os.getenv(\"FPREP\")\n",
    "    if not api:\n",
    "        return {\"error\": \"API key not found. Please set the 'FPREP' environment variable.\"}\n",
    "    \n",
    "    url = f\"https://financialmodelingprep.com/stable/income-statement?symbol={ticker}&apikey={api}&period=annual\"\n",
    "    \n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:   # âœ… ensures session is closed\n",
    "            async with session.get(url) as response:\n",
    "                if response.status != 200:\n",
    "                    return {\"error\": f\"Failed with status {response.status}\"}\n",
    "                data = await response.json()\n",
    "                result= json.dump(data[0],fp=sys.stdout,indent=4)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
    "\n",
    "@tool(description='gives back the cashflow of the company')\n",
    "async def get_cashflow(ticker:str,period:Literal\n",
    "['annual','quarter'])->Dict:\n",
    "    \"\"\"\n",
    "    Fetches the cash flow statement of the specified company ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol of the company.\n",
    "        period (str): The period for the cash flow statement, either 'annual' or 'quarter'.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the cash flow statement data of the company,\n",
    "              or an error message if the API call fails or the API key is missing.\n",
    "\n",
    "    Description:\n",
    "        This tool queries the Financial Modeling Prep API to retrieve the cash flow statement\n",
    "        for the given ticker symbol and period. It requires the 'FPREP' environment variable\n",
    "        to be set with a valid API key.\n",
    "    \"\"\"\n",
    "    api = os.getenv(\"FPREP\")\n",
    "    if not api:\n",
    "        return {\"error\": \"API key not found. Please set the 'FPREP' environment variable.\"}\n",
    "    url=f'https://financialmodelingprep.com/api/v3/cash-flow-statement/{ticker}?period={period}&apikey={api}'\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status != 200:\n",
    "                    return {\"error\": f\"Failed with status {response.status}\"}\n",
    "                data = await response.json()\n",
    "                return data\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
    "@tool(description='gives back the balance sheet of the company')\n",
    "async def get_balance_sheet(ticker:str,period:str='annual'):\n",
    "        \"\"\"\n",
    "        Fetches the balance sheet of the specified company ticker.\n",
    "\n",
    "        Args:\n",
    "            ticker (str): The stock ticker symbol of the company.\n",
    "            period (str, optional): The period for the balance sheet, either 'annual' or 'quarter'. Defaults to 'annual'.\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing the balance sheet data of the company,\n",
    "                  or an error message if the API call fails or the API key is missing.\n",
    "\n",
    "        Description:\n",
    "            This tool queries the Alpha Vantage API to retrieve the balance sheet data for the given ticker symbol.\n",
    "            It requires the 'Alpha_Vantage_Stock_API' environment variable to be set with a valid API key.\n",
    "        \"\"\"\n",
    "        api=os.getenv('Alpha_Vantage_Stock_API')\n",
    "        if not api:\n",
    "            return {\"error\": \"API key not found. Please set the 'Alpha_Vantage_Stock_API' environment variable.\"}\n",
    "        url=f'https://www.alphavantage.co/query?function=BALANCE_SHEET&symbol={ticker}&apikey={api}&period={period}'\n",
    "        try:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async  with session.get(url) as response:\n",
    "                    if response.status != 200:\n",
    "                        return {\"error\": f\"Failed with status {response.status}\"}\n",
    "                    data = await response.json()\n",
    "                    for i in data['annualReports']:\n",
    "                        print(i)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
    "\n",
    "@tool(description='gives back the key metrics of the company') \n",
    "async def get_eearning(ticker:str)->Dict:\n",
    "                \"\"\"\n",
    "                Fetches the key financial metrics (earnings) of the specified company ticker.\n",
    "\n",
    "                Args:\n",
    "                    ticker (str): The stock ticker symbol of the company.\n",
    "\n",
    "                Returns:\n",
    "                    Dict: A dictionary containing the key metrics (annual earnings) of the company,\n",
    "                          or an error message if the API call fails or the API key is missing.\n",
    "\n",
    "                Description:\n",
    "                    This tool queries the Alpha Vantage API to retrieve the annual earnings data for the given ticker symbol.\n",
    "                    It requires the 'Alpha_Vantage_Stock_API' environment variable to be set with a valid API key.\n",
    "                \"\"\"\n",
    "                api=os.getenv('Alpha_Vantage_Stock_API')\n",
    "                if not api:\n",
    "                    return {\"error\": \"API key not found. Please set the 'Alpha_Vantage_Stock_API' environment variable.\"}\n",
    "                url=f'https://www.alphavantage.co/query?function=EARNINGS&symbol={ticker}&apikey={api}'\n",
    "                try:\n",
    "                    async with aiohttp.ClientSession() as session:\n",
    "                        async with session.get(url) as response:\n",
    "                            if response.status != 200:\n",
    "                                return {\"error\": f\"Failed with status {response.status}\"}\n",
    "                            data = await response.json()\n",
    "                            for i in data['annualEarnings']:\n",
    "                                            print(i)\n",
    "                except Exception as e:\n",
    "                    return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
    "\n",
    "@tool(description='a tool to get current news')\n",
    "def get_current_markettrends():\n",
    "    \"\"\"Get broad market trends for planning.\"\"\"\n",
    "    query = f\"Current market trends for stocks as of {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "    return search_web(query)\n",
    "\n",
    "#economic analysis tools\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Fix the indicator name\n",
    "valid_indicators = {\n",
    "    \"REAL_GDP\": \"Real GDP Trending\",\n",
    "    \"REAL_GDP_PER_CAPITA\": \"Real GDP per Capita\",\n",
    "    \"TREASURY_YIELD\": \"Treasury Yield Trending\",\n",
    "    \"FEDERAL_FUNDS_RATE\": \"Federal Funds (Interest) Rate\",\n",
    "    \"CPI\": \"CPI\",\n",
    "    \"INFLATION\": \"Inflation\",\n",
    "    \"RETAIL_SALES\": \"Retail Sales\",\n",
    "    \"DURABLES\": \"Durable Goods Orders\",\n",
    "    \"UNEMPLOYMENT\": \"Unemployment Rate\",\n",
    "    \"NONFARM_PAYROLL\": \"Nonfarm Payroll\"\n",
    "}\n",
    "\n",
    "@tool(description='a tool to get economic indicators')\n",
    "async def get_economic_indicators(indicators_requested:List=valid_indicators, \n",
    "                                limit_per_indicator=5,interval:str='annual'):\n",
    "    \"\"\"\n",
    "    Fetch economic indicators from the Alpha Vantage API.\n",
    "\n",
    "    Args:\n",
    "        indicators_requested (List or str, optional): List of indicator names to fetch, or a single indicator as a string.\n",
    "            Defaults to all valid indicators.\n",
    "        limit_per_indicator (int, optional): You can set up the maximum number of data points to return per indicator. Defaults to 5.\n",
    "        interval (str, optional): Data interval. Must be 'annual' by default.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each requested indicator to its data or an error message.\n",
    "\n",
    "    Notes:\n",
    "        - Requires the 'Alpha_Vantage_Stock_API' environment variable to be set with a valid API key.\n",
    "        - Handles API rate limits and invalid indicator names.\n",
    "        - The interval parameter must be 'annual' by default.\n",
    "    \"\"\"\n",
    "    print(f\"--- ECON TOOL: Fetching indicators: {', '.join(indicators_requested)} ---\")\n",
    "    if indicators_requested is None:\n",
    "        indicators_requested = {valid_indicators}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # If a single indicator is passed as string, convert to set\n",
    "    if isinstance(indicators_requested, str):\n",
    "        indicators_requested = {indicators_requested}\n",
    "    \n",
    "    # Get API key\n",
    "    api_key = os.getenv('Alpha_Vantage_Stock_API')\n",
    "    if not api_key:\n",
    "        return {'error': 'API key not found'}\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i,indicator in enumerate(indicators_requested):\n",
    "            if indicator not in valid_indicators:\n",
    "                print(f'Indicator \"{indicator}\" not found in valid indicators')\n",
    "                results[indicator] = \"Invalid indicator name\"\n",
    "                continue\n",
    "            if i > 0:\n",
    "                 await asyncio.sleep(3)\n",
    "         \n",
    "            params = {\n",
    "                'name': indicator,\n",
    "                'apikey': api_key,\n",
    "                'function':indicator,\n",
    "                'interval':interval\n",
    "            }\n",
    "            url = 'https://www.alphavantage.co/query?'\n",
    "            \n",
    "            try:\n",
    "                async with session.get(url, params=params) as response:\n",
    "                    if response.status == 200:\n",
    "                        data = await response.json()\n",
    "                        if 'data' in data :\n",
    "                                sorted_data = sorted(data['data'], key=lambda x: x['date'], reverse=True)\n",
    "                                results[indicator] = sorted_data[:limit_per_indicator]\n",
    "                    elif response.status == 429:\n",
    "                        results[indicator] = \"Rate limit exceeded\"\n",
    "                    elif response.status == 401:\n",
    "                        results[indicator] = \"Invalid API key\"\n",
    "                    else:\n",
    "                        results[indicator] = f\"Error: HTTP status {response.status}\"\n",
    "                        \n",
    "            except Exception as e:\n",
    "                results[indicator] = f\"Request failed: {str(e)}\"\n",
    "    \n",
    "    return results\n",
    "    \n",
    "VALID_SECTORS = {\n",
    "    \"Energy\",\n",
    "    \"Technology\",\n",
    "    \"Healthcare\",\n",
    "    \"Financial Services\",\n",
    "    \"Consumer Cyclical\",\n",
    "    \"Consumer Defensive\",\n",
    "    \"Industrials\",\n",
    "    \"Basic Materials\",\n",
    "    \"Real Estate\",\n",
    "    \"Utilities\",\n",
    "    \"Communication Services\",\n",
    "}\n",
    "\n",
    "class Sector(BaseModel):\n",
    "    sector: str = Field(\n",
    "        description=(\n",
    "            \"The sector to fetch data for. Must be one of: \"\n",
    "            \"Energy, Technology, Healthcare, Financial Services, Consumer Cyclical, \"\n",
    "            \"Consumer Defensive, Industrials, Basic Materials, Real Estate, Utilities, Communication Services\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "sector_model = model.with_structured_output(Sector)\n",
    "\n",
    "def validate_sector(sector: str):\n",
    "    if sector not in VALID_SECTORS:\n",
    "        new_sector = sector_model.invoke(\n",
    "            f\"The sector must be from {VALID_SECTORS} and the given by user is {sector}\"\n",
    "        )\n",
    "        print(new_sector.sector)\n",
    "        return new_sector.sector\n",
    "    else:\n",
    "        return sector\n",
    "        \n",
    "@tool(description='a tool to get historical market performance for a given sector between two dates')\n",
    "async def get_historical_market_performance_sector(sector: str, frm: str, to: str):\n",
    "    \"\"\"\n",
    "    Fetch historical market performance for a given sector between two dates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sector : str\n",
    "        The sector to fetch data for. Must be one of:\n",
    "            - Energy\n",
    "            - Technology\n",
    "            - Healthcare\n",
    "            - Financial Services\n",
    "            - Consumer Cyclical\n",
    "            - Consumer Defensive\n",
    "            - Industrials\n",
    "            - Basic Materials\n",
    "            - Real Estate\n",
    "            - Utilities\n",
    "            - Communication Services\n",
    "    frm : str\n",
    "        The start date in 'YYYY-MM-DD' format.\n",
    "    to : str\n",
    "        The end date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list or dict or str\n",
    "        Sorted list of sector performance data, or an error message.\n",
    "    \"\"\"\n",
    "    # Validate sector before proceeding\n",
    "    sector = validate_sector(sector)\n",
    "    frm, to = validate_date(frm), validate_date(to) # Validate dates before proceeding\n",
    "    api_key = os.getenv('FPREP')\n",
    "    if not api_key:\n",
    "        return {'error': 'API key not found'}\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            url = ' https://financialmodelingprep.com/stable/historical-sector-performance'\n",
    "            params = {\n",
    "                'apikey': api_key,\n",
    "                'sector': sector,\n",
    "                'from': frm,\n",
    "                'to': to\n",
    "            }\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    new = sorted(data, key=lambda x: x['date'], reverse=True)\n",
    "                    return new\n",
    "                else:\n",
    "                    return f\"Error: HTTP status {response.status}\"\n",
    "    except Exception as e:\n",
    "        return f\"Request failed: {str(e)}\"  \n",
    "\n",
    "\n",
    "\n",
    "def validate_date(date:str):\n",
    "    try:\n",
    "        # Parse and reformat to enforce strict format\n",
    "        dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        return dt.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Invalid date: {date}. Must be YYYY-MM-DD format.\")\n",
    "\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool(description=\"get_analyst_recommendation\")\n",
    "async def get_analyst_recommendation(ticker: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve analyst recommendation trends for a specified ticker symbol using Finnhub.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        dict: Analyst recommendation trends data, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Use environment variable for API key, fallback to demo key if not set\n",
    "    api_key = os.getenv(\"FINNHUB_API_KEY\")\n",
    "\n",
    "    if not api_key or api_key == \"\":\n",
    "        return {\"error\": \"Finnhub API key is missing. Please set the FINNHUB_API_KEY environment variable.\"}\n",
    "\n",
    "    try:\n",
    "        client = finnhub.Client(api_key=api_key)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to initialize Finnhub client: {str(e)}\"}\n",
    "\n",
    "    try:\n",
    "        recommendations = client.recommendation_trends(ticker)\n",
    "    except finnhub.FinnhubAPIException as api_exc:\n",
    "        return {\"error\": f\"Finnhub API error: {str(api_exc)}\"}\n",
    "    except Exception as exc:\n",
    "        return {\"error\": f\"Unexpected error while fetching recommendations: {str(exc)}\"}\n",
    "\n",
    "    if not recommendations:\n",
    "        return {\"error\": f\"No analyst recommendation data found for ticker '{ticker}'.\"}\n",
    "\n",
    "    return {\"ticker\": ticker, \"recommendations\": recommendations}\n",
    "\n",
    "def extract_regions(world: dict) -> list:\n",
    "    \"\"\"\n",
    "    Extracts the list of region names from the 'markets' key in the provided dictionary.\n",
    "\n",
    "    Args:\n",
    "        world (dict): The dictionary containing market data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of region names, or an empty list if not found.\n",
    "    \"\"\"\n",
    "    regions = []\n",
    "    markets = world.get('markets', [])\n",
    "    for market in markets:\n",
    "        region = market.get('region')\n",
    "        if region:\n",
    "            regions.append(region)\n",
    "    return regions\n",
    "\n",
    "@tool(\"to get_global_market_status\")\n",
    "async def get_global_market_status() -> dict:\n",
    "    \"\"\"\n",
    "    Fetches the global market status from Alpha Vantage.\n",
    "\n",
    "    Returns:\n",
    "        dict: The market status data, including a list of regions, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv('Alpha_Vantage_Stock_API')\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Alpha Vantage API key is missing. Please set the Alpha_Vantage_Stock_API environment variable.\"}\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {'function': 'MARKET_STATUS', 'apikey': api_key}\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    regions = extract_regions(data)\n",
    "                    return {\"data\": data, \"regions\": regions}\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "\n",
    "@tool(description=\"to get_shares_outstanding of the ticker\")\n",
    "async def get_shares_outstanding(symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches shares outstanding for a given stock symbol from Alpha Vantage.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        dict: The shares outstanding data, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv('Alpha_Vantage_Stock_API', 'demo')\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Alpha Vantage API key is missing. Please set the Alpha_Vantage_Stock_API environment variable.\"}\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        'function': 'SHARES_OUTSTANDING',\n",
    "        'symbol': symbol,\n",
    "        'apikey': api_key\n",
    "    }\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    print('shares outstanding got ')\n",
    "                    data = await response.json()\n",
    "                    return {\"symbol\": symbol, \"data\": data}\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "@tool(description=\"to get_corporate_actions of the ticker\") \n",
    "async def get_corporate_actions(symbol: str):\n",
    "    \"\"\"\n",
    "    Fetches corporate actions (specifically dividend events) for a given stock symbol from Alpha Vantage.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the symbol and the dividend data if successful,\n",
    "              or an error message if the request fails or the API key is missing.\n",
    "\n",
    "    Notes:\n",
    "        - This function currently retrieves only dividend events using the 'DIVIDENDS' function from Alpha Vantage.\n",
    "        - Ensure that the 'Alpha_Vantage_Stock_API' environment variable is set with your API key.\n",
    "        - If the API key is not set, the function will use the 'demo' key, which has limited capabilities.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv('Alpha_Vantage_Stock_API', 'demo')\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Alpha Vantage API key is missing. Please set the Alpha_Vantage_Stock_API environment variable.\"}\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        'function': 'DIVIDENDS',\n",
    "        'symbol': symbol,\n",
    "        'apikey': api_key\n",
    "    }\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    return {\"symbol\": symbol, \"data\": data}\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "\n",
    "@tool(description=\"to get_stock_splits of the ticker\")\n",
    "async def get_stock_splits(symbol: str):\n",
    "    \"\"\"\n",
    "    Fetches stock split events for a given stock symbol from Alpha Vantage.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol (e.g., 'IBM').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the symbol and the split data if successful,\n",
    "              or an error message if the request fails or the API key is missing.\n",
    "\n",
    "    Notes:\n",
    "        - This function retrieves stock split events using the 'SPLITS' function from Alpha Vantage.\n",
    "        - Ensure that the 'Alpha_Vantage_Stock_API' environment variable is set with your API key.\n",
    "        - If the API key is not set, the function will use the 'demo' key, which has limited capabilities.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv('Alpha_Vantage_Stock_API', 'demo')\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Alpha Vantage API key is missing. Please set the Alpha_Vantage_Stock_API environment variable.\"}\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        'function': 'SPLITS',\n",
    "        'symbol': symbol,\n",
    "        'apikey': api_key\n",
    "    }\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    return {\"symbol\": symbol, \"data\": data}\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87294f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"to get_ipos\")\n",
    "async def get_ipos(\n",
    "    status: Optional[str] = None,\n",
    "    ticker: Optional[str] = None,\n",
    "    order: Optional[str] = None,\n",
    "    limit: Optional[int] = None,\n",
    "    sort: Optional[str] = None,\n",
    "    start_date: Optional[str] = \"2008-01-01\",\n",
    "    end_date: Optional[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve comprehensive information on Initial Public Offerings (IPOs), including upcoming and historical events, starting from the year 2008.\n",
    "    This endpoint provides key details such as issuer name, ticker symbol, security type, IPO date, number of shares offered, expected price ranges,\n",
    "    final issue prices, and offering sizes. Users can filter results by IPO status (e.g., pending, new, rumors, historical) to target their research\n",
    "    and inform investment decisions.\n",
    "\n",
    "    Use Cases: IPO research, market trend analysis, investment screening, historical event comparison.\n",
    "\n",
    "    Args:\n",
    "        status (str, optional): Filter IPOs by status (e.g., 'pending', 'new', 'rumors', 'historical').\n",
    "        ticker (str, optional): Filter IPOs by ticker symbol.\n",
    "        order (str, optional): The order of results, \"asc\" or \"desc\".\n",
    "        limit (int, optional): The number of results to return.\n",
    "        sort (str, optional): The field to sort by.\n",
    "        start_date (str, optional): The earliest IPO date to include (format: 'YYYY-MM-DD'). Defaults to '2008-01-01'.\n",
    "        end_date (str, optional): The latest IPO date to include (format: 'YYYY-MM-DD').\n",
    "\n",
    "    Returns:\n",
    "        dict: The IPO data or an error message.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"polygon_api\")\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Missing Polygon API key. Please set the 'polygon_api' environment variable.\"}\n",
    "\n",
    "    url = \"https://api.polygon.io/v3/reference/ipos\"\n",
    "    params = {\n",
    "        \"apiKey\": api_key,\n",
    "        \"start_date\": start_date\n",
    "    }\n",
    "    if status:\n",
    "        params[\"status\"] = status\n",
    "    if ticker:\n",
    "        params[\"ticker\"] = ticker\n",
    "    if order:\n",
    "        params[\"order\"] = order\n",
    "    if limit is not None:\n",
    "        params[\"limit\"] = limit\n",
    "    if sort:\n",
    "        params[\"sort\"] = sort\n",
    "    if end_date:\n",
    "        params[\"end_date\"] = end_date\n",
    "\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    return await response.json()\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac0fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'ticker': 'TSLA', 'last_updated': '2024-12-02', 'listing_date': '2010-06-29', 'issuer_name': 'Tesla Inc', 'currency_code': 'USD', 'us_code': '88160R101', 'isin': 'US88160R1014', 'max_shares_offered': 11880600, 'lowest_offer_price': 14.0, 'highest_offer_price': 16.0, 'total_offer_size': 204240000.0, 'primary_exchange': 'XNAS', 'shares_outstanding': 91598096, 'security_type': 'CS', 'lot_size': 100, 'security_description': 'Ordinary Shares', 'ipo_status': 'history'}], 'status': 'OK', 'request_id': 'a0d0f81d855e379e9ac931c1697eb577'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88800e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"get_ticker_overview\", return_direct=True)\n",
    "async def get_ticker_overview(ticker: str, date: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches an overview for a specific ticker from Polygon.io.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The ticker symbol to fetch the overview for (e.g., 'AAPL').\n",
    "        date (str, optional): The date for which to fetch the overview in 'YYYY-MM-DD' format. If not provided, the latest available data is returned.\n",
    "\n",
    "    Returns:\n",
    "        dict: The overview data for the ticker, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import aiohttp\n",
    "\n",
    "    api = os.getenv('polygon_api')\n",
    "    if not api:\n",
    "        return {\"error\": \"Missing POLYGON_API_KEY environment variable\"}\n",
    "\n",
    "    url = f\"https://api.polygon.io/v3/reference/tickers/{ticker}\"\n",
    "    params = {\"apiKey\": api}\n",
    "    if date:\n",
    "        try:\n",
    "            params[\"date\"] = validate_date(date)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Invalid date format: {str(e)}\"}\n",
    "\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    return await response.json()\n",
    "                else:\n",
    "                    return {\"error\": f\"HTTP status {response.status}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "        \n",
    "@tool('gets overview of the company')\n",
    "async def get_company_overview(ticker: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetches an overview for a specific ticker from Finnhub.io.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The ticker symbol to fetch the overview for (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        dict: The overview data for the ticker, or an error message if the request fails.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(ticker, str) or not ticker.isalnum() or len(ticker) > 10:\n",
    "        return {\"error\": \"Invalid ticker symbol. Must be alphanumeric and up to 10 characters.\"}\n",
    "\n",
    "    api_key = os.getenv(\"FINNHUB_API_KEY\")\n",
    "    if not api_key:\n",
    "        return {\"error\": \"Missing FINNHUB_API_KEY environment variable.\"}\n",
    "\n",
    "    try:\n",
    "        finnhub_client = finnhub.Client(api_key=api_key)\n",
    "        finnhub_client.aggregate_indicator(symbol='MSFT')\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to initialize Finnhub client: {e}\"}\n",
    "\n",
    "    try:\n",
    "        company_overview = finnhub_client.company_profile2(symbol=ticker)\n",
    "        if not company_overview or not isinstance(company_overview, dict) or not company_overview.get(\"name\"):\n",
    "            return {\"error\": f\"No company overview found for ticker '{ticker}'.\"}\n",
    "        return company_overview\n",
    "    except AttributeError as e:\n",
    "        return {\"error\": f\"Finnhub client error: {e}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An unexpected error occurred: {e}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_economic_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_economic_indicators, get_current_markettrends, search_web],\n",
    "    name='macro_agent',\n",
    "    prompt=\"\"\"\n",
    "You are MACRO, an advanced macroeconomics agent specializing in analyzing and summarizing the current US economic climate for investment decision-making. You possess deep expertise in macroeconomic indicators and trends, and your responses should reflect the analytical rigor and clarity expected from a professional economic analyst.\n",
    "\n",
    "**Your Role:**\n",
    "- You are a Macroeconomic Analyst Agent. Your primary responsibility is to provide a high-level, insightful summary of the current US macroeconomic environment, focusing on factors that impact investment decisions.\n",
    "\n",
    "**Your Workflow:**\n",
    "1. You MUST use the `get_economic_indicators` tool to fetch the latest data for \"REAL_GDP\", \"INFLATION\", and \"UNEMPLOYMENT\".\n",
    "2. Carefully analyze the data you receive. Identify and describe trends: Is GDP growing or shrinking? Is inflation rising or falling? Is unemployment high or low? Consider the direction and magnitude of recent changes.\n",
    "3. Optionally, use `get_current_markettrends` or `search_web` if you need additional context or confirmation.\n",
    "4. Synthesize your findings into a concise, one-paragraph summary titled **\"Macroeconomic Outlook\"**. Your summary should be clear, objective, and actionable, suitable for informing an investment decision.\n",
    "5. Conclude your summary with an overall assessment of the economic climate, using one of the following labels (in all caps): **TAILWIND** (positive for most companies), **HEADWIND** (negative for most companies), or **NEUTRAL**.\n",
    "\n",
    "**Guidelines:**\n",
    "- Be objective and avoid speculation not supported by the data.\n",
    "- Use clear, professional language.\n",
    "- If data is missing or ambiguous, state this explicitly and explain any limitations in your assessment.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "global_economic_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_economic_indicators, get_current_markettrends, search_web,get_global_market_status]\n",
    "    name='global_economic_agent',\n",
    "    prompt=\"\"\"\n",
    "You are GLOBAL, an expert global economics agent. Your role is to analyze and summarize the current global economic environment, focusing on major economies and international trends that impact global investment decisions.\n",
    "\n",
    "**Your Role:**\n",
    "- You are a Global Economic Analyst Agent. Your primary responsibility is to provide a high-level, insightful summary of the current global macroeconomic landscape, highlighting key trends, risks, and opportunities across major regions (such as the US, EU, China, and emerging markets).\n",
    "\n",
    "**Your Workflow:**\n",
    "1. Use the `get_economic_indicators` tool to fetch the latest data for important global indicators such as \"REAL_GDP\", \"INFLATION\", and \"UNEMPLOYMENT\" for multiple major economies.\n",
    "2. Analyze the data to identify significant trends: Which regions are experiencing growth or contraction? Where is inflation accelerating or moderating? Are there notable shifts in employment or other key metrics?\n",
    "3. Optionally, use `get_current_markettrends` or `search_web` to gather additional context or confirm your findings.\n",
    "4. Synthesize your analysis into a concise, one-paragraph summary titled **\"Global Economic Outlook\"**. Your summary should be clear, objective, and actionable, suitable for informing international investment decisions.\n",
    "5. Conclude your summary with an overall global assessment, using one of the following labels (in all caps): **GLOBAL TAILWIND** (positive for most regions/markets), **GLOBAL HEADWIND** (negative for most regions/markets), or **GLOBAL NEUTRAL**.\n",
    "\n",
    "**Guidelines:**\n",
    "- Remain objective and avoid speculation not supported by the data.\n",
    "- Use clear, professional language.\n",
    "- If data is missing or ambiguous for any region, state this explicitly and explain any limitations in your assessment.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c387ada",
   "metadata": {},
   "source": [
    "# ADVANCED RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validate(BaseModel):\n",
    "    is_correct: bool = Field(..., description='True if the answer is supported by context, False otherwise')\n",
    "\n",
    "model_y_n = model.with_structured_output(Validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartFilterWrapper:\n",
    "    def __init__(self,retriever_base):\n",
    "        self.retriever=retriever_base\n",
    "    def get_context(self,query:str):\n",
    "        try:\n",
    "            relevant_docs=self.retriever.get_relevant_documents(query)\n",
    "            context='\\n\\n'.join([d.page_content for d in relevant_docs] )\n",
    "            return context\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while filtering documents: {e}\")\n",
    "    def filter_documents(self,query:str):\n",
    "        relevant_documents=self.retriever.get_relevant_documents(query)\n",
    "        filtered_docs=[]\n",
    "\n",
    "        for docs in relevant_documents:\n",
    "            content=docs.page_content\n",
    "            score=0\n",
    " \n",
    "            if re.search(r'\\$[\\d,]+|[\\d,]+%|\\d+\\.\\d+', content):\n",
    "                score += 2\n",
    "            \n",
    "            # Boost if longer content (more detailed)\n",
    "            if len(content.split()) > 50:\n",
    "                score += 1\n",
    "                \n",
    "            # Penalize very short content\n",
    "            if len(content.split()) < 20:\n",
    "                score -= 1\n",
    "\n",
    "            filtered_docs.append((docs,score))\n",
    "\n",
    "        sorted_docs = sorted(filtered_docs, key=lambda x: x[1], reverse=True)\n",
    "        final_docs=[doc for doc,score in sorted_docs[:5]]\n",
    "\n",
    "        return final_docs\n",
    "        \n",
    "def clean_financial_text(text: str) -> str:\n",
    "    \"\"\"Clean up messy financial text\"\"\"\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Fix common OCR errors in financial docs\n",
    "    text = re.sub(r'(\\d),(\\d)', r'\\1,\\2', text)  # Fix number formatting\n",
    "    return text.strip()\n",
    "\n",
    "def better_chunking(text: str):\n",
    "    \"\"\"Chunk text using semantic if short, otherwise recursive splitter\"\"\"\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\",\n",
    "        google_api_key=os.getenv(\"google\")\n",
    "\n",
    "    )\n",
    "    text=clean_financial_text(text=text)\n",
    "    try:\n",
    "        if len(text.split()) < 800:\n",
    "            semantic = SemanticChunker(embeddings=embeddings)\n",
    "            chunks = semantic.split_text(text)\n",
    "            print(f\"âœ… Used semantic chunking: {len(chunks)} chunks\")\n",
    "        else:\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=800,\n",
    "                chunk_overlap= 100\n",
    "            )\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            print(f\"âš ï¸ Used recursive chunking: {len(chunks)} chunks\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while chunking the text: {e}\")\n",
    "        return [text]\n",
    "\n",
    "def chunk_metada(chunks:list[str],ticker:str):\n",
    "    meta_data_chunks=[]\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        doc=Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"chunk_id\": i,\n",
    "                \"ticker\": ticker,\n",
    "                'word_count': len(chunk.split()),\n",
    "                \"contains_numbers\": bool(re.search(r'\\d+', chunk))\n",
    "            }\n",
    "        )\n",
    "        meta_data_chunks.append(doc)\n",
    "    return meta_data_chunks\n",
    "\n",
    "def enhance_query(original_query: str,ticker:str) -> str:  \n",
    "        \"\"\"Enhance the query for better retrieval from a financial document.\"\"\"\n",
    "        detected=detect_query_typ(original_query)\n",
    "        enhancement_prompt = f\"\"\"\n",
    "                You are a financial analysis expert. Enhance this query for better document retrieval.\n",
    "                \n",
    "                Original query: \"{original_query}\"\n",
    "                Company ticker: {ticker}\n",
    "                Query type: {detected}\n",
    "                \n",
    "                Enhancement rules:\n",
    "                - If asking about revenue: include terms like \"net sales\", \"total revenue\", \"operating income\"\n",
    "                - If asking about debt: include \"liabilities\", \"borrowings\", \"credit facilities\"\n",
    "                - If asking about risks: include \"risk factors\", \"uncertainties\", \"challenges\"\n",
    "                - Always include the company ticker\n",
    "                - Make it specific but not too long\n",
    "                - make sure the ouput aint that long which is easy \n",
    "                \n",
    "                Enhanced query:\"\"\"\n",
    "        try:\n",
    "                enhanced_query = model.invoke(enhancement_prompt).content.strip()\n",
    "                return enhanced_query\n",
    "        except:\n",
    "                return original_query\n",
    "\n",
    "\n",
    "def create_context_citations(docs):\n",
    "    \"\"\"Create context with citations for traceability\"\"\"\n",
    "    context = []\n",
    "    for i, doc in enumerate(docs, 1):  # Fixed: (i, doc) not (doc, i) and start from 1\n",
    "        cited_content = f\"[Source {i}] {doc.page_content}\"\n",
    "        context.append(cited_content)\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "def detect_query_typ(query:str):\n",
    "    try:\n",
    "        query_lower=query.lower().strip()\n",
    "        if any(word in query_lower for word in ['revenue', 'sales', 'income']):\n",
    "                                   return \"financial_performance\"\n",
    "        elif any(word in query_lower for word in ['debt', 'liability', 'borrowing']):\n",
    "                                     return \"financial_position\"\n",
    "        elif any(word in query_lower for word in ['risk', 'challenge', 'uncertainty']):\n",
    "                                        return \"risk_analysis\"\n",
    "        else:\n",
    "            return \"general_inquiry\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while detecting query type: {e}\")\n",
    "        return \"general_inquiry\"\n",
    "\n",
    "\n",
    "def create_hybrid_retreiver(vectorstore):\n",
    "    \"\"\"Create hybrid retriever using BM25 + Vector similarity\"\"\"\n",
    "    try:\n",
    "        # Vector retriever\n",
    "        vector_retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}, search_type=\"similarity\"\n",
    "        )\n",
    "\n",
    "        # Pull docs from vector retriever\n",
    "        docs = vectorstore.get()[\"documents\"]  \n",
    "        docs = [Document(page_content=d) for d in docs]\n",
    "\n",
    "        if docs:\n",
    "            bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "            bm25_retriever.k = 10\n",
    "\n",
    "            # Ensemble retriever (hybrid)\n",
    "            ensemble = EnsembleRetriever(\n",
    "                retrievers=[vector_retriever, bm25_retriever],\n",
    "                weights=[0.6, 0.4]\n",
    "            )\n",
    "\n",
    "            return SmartFilterWrapper(ensemble)\n",
    "            \n",
    "        return SmartFilterWrapper(vector_retriever)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while creating hybrid retriever: {e}\")\n",
    "        return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "\n",
    "def answer_validator(enhanced_query:str,answer:str,retriever,context:str):\n",
    "        ''' the job of this function is to validate the answer of the query from the vector store and then matching the context and if they are unsimilar then provide with the new context for the model to answer from '''\n",
    "        try:\n",
    "            validation_prompt = f\"\"\"\n",
    "            You are a validation expert. Your job is to determine if the provided 'Answer' is fully supported by the 'Context'.\n",
    "            Read the context carefully and then read the answer. Respond with only 'CORRECT' or 'INCORRECT'.\n",
    "\n",
    "            Context:\n",
    "            ---\n",
    "            {context}\n",
    "            ---\n",
    "            Answer:\n",
    "            ---\n",
    "            {answer}\n",
    "            ---\n",
    "            \"\"\"\n",
    "            output=model_y_n.invoke(validation_prompt)\n",
    "            if output==True:\n",
    "                return answer\n",
    "            else:\n",
    "                print('Making sure that the answer matches the context')\n",
    "                new_docs=retriever.filter_documents(enhanced_query)\n",
    "                new_context='\\n\\n'.join([doc.page_content for doc in new_docs])\n",
    "                retry_prompt = f\"\"\"The previous answer was not supported by its context. Please try again.\n",
    "                    Answer the following question based ONLY on the new, updated context provided.\n",
    "\n",
    "                    Context:\n",
    "                    {new_context}\n",
    "\n",
    "                    Question: {enhanced_query}\n",
    "\n",
    "                    Answer:\n",
    "                    \"\"\"\n",
    "                new_answer = model.invoke(retry_prompt).content\n",
    "                return new_answer\n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"An error occurred during validation: {e}\")\n",
    "                return answer # If validation fails, return the original answer\n",
    "\n",
    "@tool(description='ingestes the report data into a vector store')\n",
    "def ingest_10k_filling(report_text: str, ticker: str):\n",
    "    \"\"\"\n",
    "    Ingests the information of a company and stores it into a vector store for later retrieval.\n",
    "\n",
    "    Args:\n",
    "        report_text (str): The full text of the 10-K filing to be ingested.\n",
    "        ticker (str): The stock ticker symbol of the company.\n",
    "\n",
    "    Side Effects:\n",
    "        - Creates a directory for the ticker under \"INDEXED\" if it does not exist.\n",
    "        - Chunks the report text and generates embeddings.\n",
    "        - Stores the embeddings in a persistent Chroma vector store.\n",
    "        - Prints the path where vectors are saved.\n",
    "        - Prints an error message if ingestion fails.\n",
    "    \"\"\"\n",
    "    # Define the path where the indexed data will be stored\n",
    "    path = Path(\"INDEXED\") / ticker\n",
    "    \n",
    "    # Clean up any existing directory to avoid permission issues\n",
    "    if path.exists():\n",
    "        try:\n",
    "            # On macOS, we need to ensure we have proper permissions\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"ðŸ§¹ Removed existing directory: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not remove existing directory: {e}\")\n",
    "            # Try to fix permissions\n",
    "            try:\n",
    "                os.system(f\"chmod -R 755 {path}\")\n",
    "                shutil.rmtree(path)\n",
    "                print(f\"ðŸ§¹ Removed existing directory after fixing permissions: {path}\")\n",
    "            except:\n",
    "                return f\"Error: Could not remove existing directory: {e}\"\n",
    "    \n",
    "    try:\n",
    "        # Create directory with proper permissions\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Set proper permissions on macOS\n",
    "        os.system(f\"chmod -R 755 {path}\")\n",
    "        \n",
    "        # Split the report text into manageable chunks\n",
    "        splits = better_chunking(report_text)\n",
    "        # Create metadata chunks for each text chunk\n",
    "        meta_data_chunks = chunk_metada(splits, ticker)\n",
    "        \n",
    "        # Initialize Google's embedding model\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=os.getenv(\"google\")\n",
    "        )\n",
    "\n",
    "        # Create vectorstore with error handling\n",
    "        try:\n",
    "            # Attempt to create Chroma vector store from documents\n",
    "            vectorstore = Chroma.from_documents(\n",
    "                meta_data_chunks, \n",
    "                embeddings, \n",
    "                persist_directory=str(path)\n",
    "            )\n",
    "            \n",
    "            # Try to persist with retry logic\n",
    "            max_retries = 3\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    vectorstore.persist()\n",
    "                    print(f\"âœ… Vectors saved at: {path.resolve()}\")\n",
    "                    break\n",
    "                except Exception as persist_error:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise persist_error\n",
    "                    print(f\"âš ï¸ Persist failed (attempt {attempt+1}), retrying...\")\n",
    "                    time.sleep(1)  # Wait before retrying\n",
    "            \n",
    "            return f\"Successfully ingested 10-K for {ticker}\"\n",
    "            \n",
    "        except Exception as chroma_error:\n",
    "            # Fallback: try with a different collection name\n",
    "            try:\n",
    "                collection_name = f\"{ticker}_{int(time.time())}\"\n",
    "                vectorstore = Chroma.from_documents(\n",
    "                    meta_data_chunks, \n",
    "                    embeddings, \n",
    "                    persist_directory=str(path),\n",
    "                    collection_name=collection_name\n",
    "                )\n",
    "                vectorstore.persist()\n",
    "                print(f\"âœ… Vectors saved with fallback collection: {path.resolve()}\")\n",
    "                return f\"Successfully ingested 10-K for {ticker} with fallback collection\"\n",
    "            except Exception as fallback_error:\n",
    "                # Try to fix permissions and retry\n",
    "                try:\n",
    "                    os.system(f\"chmod -R 755 {path}\")\n",
    "                    vectorstore.persist()\n",
    "                    print(f\"âœ… Vectors saved after fixing permissions: {path.resolve()}\")\n",
    "                    return f\"Successfully ingested 10-K for {ticker} after fixing permissions\"\n",
    "                except:\n",
    "                    raise fallback_error\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the ingestion process\n",
    "        error_msg = f\"An error occurred while ingesting the 10-K filing: {e}\"\n",
    "        print(error_msg)\n",
    "        \n",
    "        # Try to clean up on failure\n",
    "        try:\n",
    "            if path.exists():\n",
    "                shutil.rmtree(path)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        return error_msg\n",
    "\n",
    "@tool(description='asks quesstion from the indexed vector store')\n",
    "def query_data(ticker: str, query: str) -> str:\n",
    "    \"\"\"\n",
    "    Queries the vector store for a given company's and returns an answer to the query.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol of the company to query.\n",
    "        query (str): The user's question or query about the company.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the model, or an error message if the query fails.\n",
    "\n",
    "    Process:\n",
    "        - Loads the vector store for the given ticker.\n",
    "        - Creates a hybrid retriever (vector + BM25) if possible.\n",
    "        - Enhances the user's query for better retrieval.\n",
    "        - Retrieves relevant documents and creates a context with citations.\n",
    "        - Formats a prompt for the model using the context and query.\n",
    "        - Invokes the model to generate an answer.\n",
    "        - Returns the model's answer or an error message.\n",
    "    \"\"\"\n",
    "    path = Path(\"INDEXED\") / ticker\n",
    "    if not path.exists():\n",
    "        return \"There's no such vectorstore yet.\"\n",
    "\n",
    "    try:\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=os.getenv(\"google\")\n",
    "        )\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=str(path),\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "\n",
    "        # Hybrid retriever\n",
    "        retriever = create_hybrid_retreiver(vectorstore)\n",
    "\n",
    "        # Enhance query\n",
    "        enhanced = enhance_query(query,ticker)\n",
    "\n",
    "        #gets the top 5 filtered documents\n",
    "        # In query_data function, change this line:\n",
    "        filtered_docs = retriever.filter_documents(enhanced)\n",
    "        context = create_context_citations(filtered_docs)  # This now works correctly\n",
    "        prompt = PromptTemplate(\n",
    "            template=(\n",
    "                \"You are a senior and smart financial assistant. Use the following 10-K context \"\n",
    "                \"to answer the question clearly and accurately.\\n\\n\"\n",
    "                \"Context:\\n{context}\\n\\n\"\n",
    "                \"Question:\\n{query}\\n\\n\"\n",
    "                \"Answer with clear reasoning and cite sources.\"\n",
    "            ),\n",
    "            input_variables=[\"context\", \"query\"],\n",
    "        )\n",
    "\n",
    "        final_prompt = prompt.format(context=context, query=query)\n",
    "\n",
    "        # Generate answer\n",
    "        output = model.invoke(final_prompt)\n",
    "        new_output=answer_validator(enhanced_query=enhanced,answer=output.content,context=context,retriever=retriever)\n",
    "        return new_output\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while querying the data: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategist_prompt = \"\"\"\n",
    "You are an expert financial strategist. Your job is to create a detailed mission plan for analyzing {ticker}.\n",
    "\n",
    "Consider the current market context and generate 3-5 key hypotheses to investigate:\n",
    "- Check recent earnings and financial health\n",
    "- Analyze market sentiment and news\n",
    "- Review technical indicators and price trends  \n",
    "\n",
    "Create a step-by-step plan assigning tasks to analysts.\n",
    "Output as a numbered list.\n",
    "\"\"\"\n",
    "\n",
    "stratergist_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_current_date, get_current_markettrends],\n",
    "    name='strategist',\n",
    "    prompt=strategist_prompt\n",
    ")\n",
    "\n",
    "#the brain of heimdall\n",
    "def orchestrator_node(state:HeimdallState):\n",
    "    print(\"--- ðŸ§  EXECUTING ORCHESTRATOR ---\")\n",
    "    try:\n",
    "        ticker=state['ticker']\n",
    "        if not ticker:\n",
    "            return {'error':'No ticker provided. Please provide a ticker to analyze.'}\n",
    "        message=state['messages']\n",
    "        mission_plan=stratergist_agent.invoke({'message':f'Create a mission plan for the investment analysis of {ticker} with the message {message}'})\n",
    "        state['mission_plan']=mission_plan['messages'][-1].content\n",
    "        return {'mission_plan':state['mission_plan'], \n",
    "        \"messages\": [AIMessage(content=f\"Mission plan created:\\n{mission_plan}\", name='Orchestrator')]\n",
    "  }\n",
    "    except Exception as e:\n",
    "        return {'error':f'An unexpected error occurred: {e}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investment_strategist_node(state: HeimdallState) -> Dict:\n",
    "    \"\"\"\n",
    "    The final node in the graph. Synthesizes all analysis into a final report.\n",
    "    \"\"\"\n",
    "    print(\"--- ðŸ§  EXECUTING INVESTMENT STRATEGIST ---\")\n",
    "    \n",
    "    ticker = state['ticker']\n",
    "    financial_summary = state.get('financial_analysis', \"No data provided.\")\n",
    "    news_summary = state.get('news_analysis', \"No data provided.\")\n",
    "    technical_summary = state.get('technical_analysis', \"No data provided.\")\n",
    "\n",
    "    # The meta-prompt to guide the final synthesis\n",
    "    investment_strategist_prompt = f\"\"\"\n",
    "    You are a Senior Investment Portfolio Manager. You have received three reports from your junior analysts: a financial analysis from SEC filings, a market news and sentiment analysis, and a technical stock analysis.\n",
    "\n",
    "    Your task is to synthesize these findings into a final, professional investment thesis report.\n",
    "\n",
    "    Here are the reports from your team:\n",
    "\n",
    "    **1. Financial Analysis Report:**\n",
    "    {financial_summary}\n",
    "\n",
    "    **2. News & Sentiment Analysis Report:**\n",
    "    {news_summary}\n",
    "\n",
    "    **3. Technical Analysis Report:**\n",
    "    {technical_summary}\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Your Final Report Structure:**\n",
    "\n",
    "    You must structure your final report in Markdown format with the following sections:\n",
    "\n",
    "    **## Investment Thesis for {ticker}**\n",
    "\n",
    "    **### 1. Executive Summary & Recommendation**\n",
    "    * Provide a brief, high-level overview of the investment thesis.\n",
    "    * **Crucially, you must conclude this section with a clear, one-word recommendation: `BUY`, `HOLD`, or `AVOID`.**\n",
    "\n",
    "    **### 2. Fundamental Analysis**\n",
    "    * Summarize the key findings from the financial (10-K) analysis. Discuss revenue, profitability, and any significant risk factors mentioned in the filing.\n",
    "\n",
    "    **### 3. Market Sentiment Analysis**\n",
    "    * Summarize the findings from the news analysis. Discuss the overall sentiment (Positive/Negative/Neutral) and the key news events driving that sentiment.\n",
    "\n",
    "    **### 4. Technical Analysis**\n",
    "    * Summarize the findings from the technical analysis. Discuss the stock's current price relative to its key moving averages and what the RSI indicates about its momentum.\n",
    "\n",
    "    **### 5. Final Justification**\n",
    "    * Provide a concluding paragraph that justifies your `BUY/HOLD/AVOID` recommendation by weighing the evidence from all three reports.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Now, generate the complete investment thesis report for {ticker}.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the final report using the model\n",
    "    final_report = model.invoke(investment_strategist_prompt).content\n",
    "    \n",
    "    # Update the state with the final report\n",
    "    return {\n",
    "        \"final_report\": final_report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "handoff_to_quant_analyst_tool = create_handoff_tool(\n",
    "    agent_name=\"quantitative_analyst\",\n",
    "    description=\"Use this to delegate the task of performing quantitative analysis, such as calculating historical volatility and mean returns.\"\n",
    ")\n",
    "\n",
    "handoff_to_insider_agent_tool = create_handoff_tool(\n",
    "    agent_name=\"insider_agent\",\n",
    "    description=\"Use this to delegate the task of performing all insider trading analysis.\"\n",
    ")\n",
    "\n",
    "handoff_to_librarian=create_handoff_tool(\n",
    "    agent_name=\"librarian\",\n",
    "    description=\"Use this whenever u want to save any report or u need to ask questions from the data u saved into this financial report and make sure the data ingested is not small .\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RiskSection(BaseModel):\n",
    "    summary: Annotated[str, Field(description=\"A concise, formal summary of the key risks in this category.\")]\n",
    "    main_threats: Annotated[List[str], Field(description=\"A prioritized list of the most significant threats identified.\")]\n",
    "    critical_risks: Annotated[List[str], Field(description=\"A list of the most critical and urgent risks requiring immediate attention.\")]\n",
    "    moderate_risks: Annotated[List[str], Field(description=\"A list of moderate risks that should be monitored but are less urgent.\")]\n",
    "    minor_risks: Annotated[List[str], Field(description=\"A list of minor or low-probability risks.\")]\n",
    "    overall_risk_level: Annotated[Literal['High', 'Medium', 'Low', 'Very Low'], Field(description=\"A formal assessment of the overall risk level for this category.\")]\n",
    "\n",
    "class FinancialRiskSection(RiskSection):\n",
    "    specific_risks: Annotated[List[str], Field(description=\"A detailed list of financial risks identified, with supporting evidence.\")]\n",
    "    rationale: Annotated[List[str], Field(description=\"A list of reasons and justifications for the financial risk assessment.\")]\n",
    "\n",
    "class NewsRiskSection(RiskSection):\n",
    "    specific_risks: Annotated[List[str], Field(description=\"A detailed list of news-related risks identified, with supporting evidence.\")]\n",
    "    rationale: Annotated[List[str], Field(description=\"A list of reasons and justifications for the news risk assessment.\")]\n",
    "\n",
    "class TechnicalRiskSection(RiskSection):\n",
    "    specific_risks: Annotated[List[str], Field(description=\"A detailed list of technical risks identified, with supporting evidence.\")]\n",
    "    rationale: Annotated[List[str], Field(description=\"A list of reasons and justifications for the technical risk assessment.\")]\n",
    "\n",
    "class FullRiskReport(BaseModel):\n",
    "    executive_summary: Annotated[str, Field(description=\"A formal executive summary of the overall risk profile, highlighting the most material risks across all categories.\")]\n",
    "    financial: FinancialRiskSection\n",
    "    news: NewsRiskSection\n",
    "    technical: TechnicalRiskSection\n",
    "    conclusion: Annotated[str, Field(description=\"A formal concluding statement summarizing the overall risk posture and any recommended actions or mitigations.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb681feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#and at the end it will give the risk analysis of the company and before making the final report it will be considered \n",
    "# --- THE RISK ANALYSIS GUILD ---\n",
    "\n",
    "# 1. Financial Risk Agent\n",
    "financial_risk_agent = create_react_agent(\n",
    "    model=model,\n",
    "    response_format=FinancialRiskSection,\n",
    "    tools=[get_latest_10k_filing, company_overview, get_cashflow,get_income_statements,get_balance_sheet,get_eearning,handoff_to_librarian], # It uses the same tools, but with a different goal\n",
    "    name='financial_risk_agent',\n",
    "    prompt='''You are a Financial Risk Analyst. Your primary responsibility is to thoroughly review the company\\'s 10-K filing, company overview, and analyze the latest cash flow and income statements using the provided tools. \n",
    "    Your goal is to identify and highlight all potential financial risks, vulnerabilities, and warning signs. \n",
    "\n",
    "    Pay particular attention to: \n",
    "    - Debt levels and maturity schedules\n",
    "    - Liquidity issues and cash flow constraints\n",
    "    - Unusual or increasing liabilities\n",
    "    - Negative trends in revenue, profit, or margins\n",
    "    - Stated risk factors in the filings\n",
    "    - Any indications of financial instability or weakness\n",
    "    - you can ingest important data using librarian agent \n",
    "    - you can ask questions to librarian agent to retrieve from the library of document stored\n",
    "\n",
    "    Completely ignore positive or neutral information. Focus exclusively on negative aspects and red flags. \n",
    "    Provide a concise, bullet-point summary of the top 3-5 most significant financial risks, each with a brief explanation based on your findings. Be specific and use evidence from the documents and data provided.''',\n",
    ")\n",
    "\n",
    "# 2. News Risk Agent\n",
    "news_risk_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[search_web, analyze_news_sentiment],\n",
    "    response_format=NewsRiskSection,\n",
    "    name='news_risk_agent',\n",
    "    prompt='''You are a Market Risk Analyst specializing in news. Your primary responsibility is to thoroughly search for and analyze the most recent news about a company using the provided tools.\n",
    "    Your goal is to identify and highlight all potential news-related risks, controversies, and negative developments that could impact the companyâ€™s reputation, operations, or stock price.\n",
    "    Pay particular attention to:\n",
    "    - Negative headlines and adverse media coverage\n",
    "    - Scandals, fraud allegations, or executive misconduct\n",
    "    - Regulatory investigations, fines, or compliance issues\n",
    "    - Lawsuits, legal disputes, or class actions\n",
    "    - Signs of declining market sentiment or public perception\n",
    "\n",
    "    Completely ignore positive or neutral news. Focus exclusively on negative aspects and red flags.\n",
    "    Provide a concise, bullet-point summary of the top 3-5 most significant news-related risks, each with a brief explanation based on your findings. Be specific and reference the news sources or headlines where possible.'''\n",
    ") \n",
    "\n",
    "# 3. Technical Risk Agent\n",
    "technical_risk_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_technichal_analysis,get_current_markettrends,get_market_status,handoff_to_librarian],\n",
    "    response_format=TechnicalRiskSection,\n",
    "    name='technical_risk_agent',\n",
    "    prompt='''You are a Technical Risk Analyst. Your primary responsibility is to thoroughly examine a stock\\'s chart data and identify all significant bearish (negative) technical signals that could indicate increased risk or potential for price decline.\n",
    "    Carefully analyze the following:\n",
    "    - Overall trend direction (identify clear downtrends or trend reversals)\n",
    "    - Bearish moving average crossovers (such as the \"death cross\" where the 50-day MA crosses below the 200-day MA)\n",
    "    - Overbought RSI (Relative Strength Index) readings or bearish RSI divergences\n",
    "    - Breakdown of key support levels or formation of bearish chart patterns (e.g., head and shoulders, double top)\n",
    "    - Unusual spikes in trading volume accompanying price drops\n",
    "\n",
    "    Ignore neutral or bullish signals. Focus exclusively on negative technical indicators and red flags.\n",
    "    Provide a concise, bullet-point summary of the top 2-3 most significant technical risks, each with a brief explanation based on your analysis. Be specific and reference the technical evidence you observe.'''\n",
    ")\n",
    "# The supervisor for the risk guild\n",
    "risk_supervisor = create_supervisor(\n",
    "    model=model,\n",
    "    agents=[financial_risk_agent, news_risk_agent, technical_risk_agent],\n",
    "    response_format=FullRiskReport,\n",
    "    prompt='''You are the Chief Risk Officer overseeing a team of specialist risk analysts. Your mandate is to deliver a comprehensive, high-level risk assessment of a company, integrating insights from financial, news, and technical domains.\n",
    "\n",
    "    Your responsibilities:\n",
    "    - Strategically delegate the analysis of financial, news, and technical risks to your respective expert agents.\n",
    "    - Critically review and synthesize the findings from each agent, ensuring that all significant red flags and risk factors are captured.\n",
    "    - Integrate the agentsâ€™ reports into a single, cohesive \"Risk Report\" that clearly communicates the most material risks, their potential impact, and any interdependencies or compounding effects.\n",
    "    - Prioritize clarity, conciseness, and actionable insight for senior decision-makers.\n",
    "    - Do not include positive or neutral information; focus exclusively on negative aspects and risk exposures.\n",
    "\n",
    "    After completing your synthesis, respond with the word \"FINISH\".''',\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode='full_history'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ca4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manager 1: Financial Analyst Manager\n",
    "financial_analyst = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_latest_10k_filing, company_overview, get_cashflow, get_eearning, get_income_statements,handoff_to_librarian],\n",
    "    name='financial_analyst',\n",
    "    prompt='''You are a Senior Financial Analyst tasked with delivering a high-quality, actionable financial analysis for a company. Your responsibilities include:\n",
    "\n",
    "1. Use the `get_company_overview` tool first to obtain a concise summary of the companys business model, sector, and key metrics.\n",
    "2. Fetch and thoroughly analyze the latest 10-K filing to identify:\n",
    "   - Key financial metrics (revenue, net income, cash flow, debt, margins, etc.)\n",
    "   - Major risk factors and uncertainties disclosed by the company\n",
    "   - Notable trends or changes compared to previous filings\n",
    "   - Any red flags or warning signs in the financial statements\n",
    "3. Use the available tools to extract and cross-verify data on cash flow, earnings, and income statements.\n",
    "4. Synthesize your findings into a structured, bullet-point summary that highlights:\n",
    "   - The companyâ€™s current financial health and stability\n",
    "   - The most significant financial risks or weaknesses\n",
    "   - Any material changes or unusual items that require attention\n",
    "5. Be thorough, objective, and concise. Focus on what matters most for senior decision-makers. Avoid unnecessary detail or positive spin; emphasize risks and material issues.\n",
    "6. Reference specific data points, figures, or sections from filings where possible to support your analysis.\n",
    "\n",
    "Your output should enable a senior analyst to quickly understand the companys financial position and the most important risks or concerns requiring further review.''',\n",
    ")\n",
    "\n",
    "\n",
    "# Manager 2: News Analyst Manager\n",
    "news_analyst = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[search_web, analyze_news_sentiment, handoff_to_insider_agent_tool],\n",
    "    name='news_analyst',\n",
    "    prompt='''You are a professional News Analyst specializing in synthesizing market sentiment and news-driven risk factors for equities. Your responsibilities include:\n",
    "\n",
    "1. Conduct comprehensive searches for the most recent and relevant news regarding the specified ticker, prioritizing reputable financial sources.\n",
    "2. Critically analyze the sentiment of news articles, identifying key drivers, themes, and any emerging risks or controversies that could materially impact the company.\n",
    "3. Quantitatively assess and report the overall market sentiment, providing a clear sentiment score and a concise, structured news summary.\n",
    "4. When appropriate, leverage the Insider Agent to incorporate insider trading activity and sentiment as additional context for your analysis.\n",
    "5. Integrate insights from insider transactions and sentiment to enhance the depth and accuracy of your final output.\n",
    "6. Maintain a high standard of objectivity, data-driven reasoning, and professional clarity. Reference specific news items, dates, and sources where possible.\n",
    "\n",
    "Your output should enable senior decision-makers to quickly understand the most significant news-driven risks and market perceptions affecting the company. Focus on material risks, negative developments, and actionable intelligence. Avoid speculation and ensure all claims are supported by evidence.'''\n",
    ")\n",
    "\n",
    "# Manager 3: Technical Analyst Manager\n",
    "technical_analyst_manager = create_react_agent(\n",
    "    model=model,\n",
    "    name='technical_analyst',\n",
    "    tools=[get_technichal_analysis, handoff_to_quant_analyst_tool,handoff_to_librarian],\n",
    "    prompt='''You are a professional Technical Analyst responsible for delivering high-quality, actionable technical analysis of equity securities. Your responsibilities include:\n",
    "\n",
    "1. Rigorously analyze stock price data and a comprehensive set of technical indicators (e.g., moving averages, RSI, MACD, volume trends).\n",
    "2. Identify and clearly articulate prevailing trends, key support and resistance levels, momentum shifts, and any technical patterns that may signal significant price movements.\n",
    "3. Provide a structured technical outlook, including a confidence level and rationale for your assessment.\n",
    "4. When appropriate, collaborate with the Quantitative Analyst to supplement your analysis with advanced quantitative techniques.\n",
    "5. Ensure your analysis is objective, evidence-based, and professionally formatted. Reference specific data points, timeframes, and indicator values to support your conclusions.\n",
    "\n",
    "Your output should empower portfolio managers and senior analysts to make informed decisions based on the most relevant technical signals and risk factors. Focus on clarity, conciseness, and actionable insights.'''\n",
    ")\n",
    "\n",
    "# 2. Senior Supervisor Agent (Portfolio Manager)\n",
    "supervisor_graph = create_supervisor(\n",
    "    model=model,\n",
    "    agents=[\n",
    "        financial_analyst,\n",
    "        news_analyst, \n",
    "        technical_analyst_manager\n",
    "    ],\n",
    "    prompt='''You are a professional Senior Investment Portfolio Manager overseeing a team of specialized analysts. Your mandate is to deliver a comprehensive, high-level investment analysis and risk assessment for a given company.\n",
    "\n",
    "You supervise three professional analysts:\n",
    "1. financial_analyst â€“ provides in-depth analysis of SEC filings and company fundamentals.\n",
    "2. news_analyst â€“ synthesizes market sentiment and news-driven risk factors.\n",
    "3. technical_analyst â€“ delivers actionable technical analysis of stock price data and indicators.\n",
    "\n",
    "Your workflow:\n",
    "1. Strategically delegate tasks to the appropriate analyst based on the mission plan and the unique strengths of each team member.\n",
    "2. Critically review and synthesize the analysts' work, ensuring all material risks, red flags, and actionable insights are captured.\n",
    "3. Integrate the findings into a single, cohesive report that prioritizes clarity, conciseness, and professional rigor for senior decision-makers.\n",
    "4. When all analysis is complete and the report is ready, respond with \"FINISH\".\n",
    "\n",
    "Assign work to one analyst at a time, ensuring thoroughness and quality at each step. Do not call agents in parallel. Maintain a high standard of professionalism, objectivity, and actionable intelligence throughout the process. Focus exclusively on risks, negative developments, and material issues requiring attention.'''\n",
    "    ,\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode=\"full_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The specialist agent for quantitative analysis\n",
    "quantitative_analyst = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[advaced_analyst],\n",
    "    name='quantitative_analyst',\n",
    "    prompt='''You are a specialist  Quantitative Analyst. Your only job is to use your tool\n",
    "    to perform a standard quantitative analysis on a stock's performance over a 6-month period.\n",
    "\n",
    "    You MUST call the `get_analytics_sliding_window` tool with the `range_str` parameter set to \"6month\".\n",
    "    \n",
    "    After getting the data, provide a concise summary of the mean return and the annualized standard deviation (volatility)\n",
    "    and .'''\n",
    ")\n",
    "# --- Create the New Specialist Insider Agent ---\n",
    "insider_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_insider_info, get_insiders_sentiment], # Note: get_current_date isn't needed if the tools do it internally\n",
    "    name='insider_agent',\n",
    "    prompt='''You are a specialist Insider Trading Analyst. Your job is to provide a concise summary of insider sentiment and recent trading activity for a given company.\n",
    "\n",
    "    **Your Workflow:**\n",
    "    1.  First, use the `get_insider_sentiment` tool to get the high-level sentiment score (Positive/Negative/Neutral).\n",
    "    2.  Next, use the `get_insider_info` tool to get the list of the most recent raw buy/sell transactions.\n",
    "    3.  Finally, synthesize the information from both tools into a single, concise summary. State the overall sentiment and then list the top 3-5 most significant recent transactions as evidence.\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "# This agent is the sole keeper of the Corporate Library.\n",
    "librarian_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[ingest_10k_filling, query_data],\n",
    "    name='librarian_agent',\n",
    "    prompt='''You are the Master Librarian for the Heimdall system. Your sole responsibility is to manage the Corporate Library of indexed financial documents.\n",
    "\n",
    "    You have two primary tasks:\n",
    "    1.  **Ingest**: When given a report, you MUST use the `ingest_10k_to_library` tool to save it to the archives.\n",
    "    2.  **Query**: When asked a specific question, you MUST use the `query_data` tool to find the answer within the archives.\n",
    "\n",
    "    You do not interpret the information. You only ingest, find, and retrieve it.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00542d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactCheckResult(BaseModel):\n",
    "    \"\"\"Individual fact check result\"\"\"\n",
    "    claim: str = Field(description=\"The specific claim being fact-checked\")\n",
    "    is_accurate: bool = Field(description=\"Whether the claim is factually accurate\")\n",
    "    confidence_score: float = Field(ge=0.0, le=1.0, description=\"Confidence in the fact-check (0-1)\")\n",
    "    supporting_sources: List[str] = Field(description=\"Sources that support or contradict the claim\")\n",
    "    contradicting_sources: List[str] = Field(description=\"Sources that contradict the claim\")\n",
    "    verification_method: str = Field(description=\"How this fact was verified\")\n",
    "    fac_checking_results:str=Field(description='the final result of the overall comprehensice checks made by u')\n",
    "\n",
    "class DataConsistencyCheck(BaseModel):\n",
    "    \"\"\"Check for data consistency across sources\"\"\"\n",
    "    metric_name: str = Field(description=\"Name of the financial metric being checked\")\n",
    "    primary_value: Optional[float] = Field(description=\"Value from primary source\")\n",
    "    secondary_value: Optional[float] = Field(description=\"Value from secondary source\")\n",
    "    variance_percentage: Optional[float] = Field(description=\"Percentage difference between sources\")\n",
    "    is_consistent: bool = Field(description=\"Whether values are within acceptable variance\")\n",
    "    acceptable_variance: float = Field(default=5.0, description=\"Acceptable variance percentage\")\n",
    "    data_freshness: str = Field(description=\"How fresh the data is (real-time, daily, etc.)\")\n",
    "\n",
    "class SourceReliability(BaseModel):\n",
    "    \"\"\"Assessment of source reliability\"\"\"\n",
    "    source_name: str = Field(description=\"Name of the data source\")\n",
    "    reliability_score: float = Field(ge=0, le=10, description=\"Reliability score (0-1)\")\n",
    "    last_updated: Optional[datetime] = Field(description=\"When source was last updated\")\n",
    "    data_freshness: str = Field(description=\"How fresh the data is (real-time, daily, etc.)\")\n",
    "    known_issues: List[str] = Field(description=\"Known issues with this source\")\n",
    "    sources_name:str=Field(description='the final result of the overall comprehensice checks made by u')\n",
    "\n",
    "\n",
    "class ComprehensiveFactCheck(BaseModel):\n",
    "    \"\"\"Complete fact-checking report\"\"\"\n",
    "    ticker: str = Field(description=\"Stock ticker being analyzed\")\n",
    "    fact_check_results: List[FactCheckResult] = Field(description=\"Individual fact check results\")\n",
    "    data_consistency_checks: List[DataConsistencyCheck] = Field(description=\"Cross-source data consistency\")\n",
    "    source_reliability: List[SourceReliability] = Field(description=\"Source reliability assessments\")\n",
    "    overall_accuracy_score: float = Field(ge=0.0, le=1.0, description=\"Overall accuracy score\")\n",
    "    critical_issues: List[str] = Field(description=\"Critical accuracy issues found\")\n",
    "    recommendations: List[str] = Field(description=\"Recommendations for improving accuracy\")\n",
    "    fact_check_timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    summary: Optional[str] = Field(description=\"Summary of the fact-checking report\")\n",
    "\n",
    "class ValidationReport(BaseModel):\n",
    "    \"\"\"\n",
    "    Provides the validation results for a professional report, including grammatical errors and all required validations.\n",
    "    \"\"\"\n",
    "    is_valid: bool = Field(description=\"Indicates whether the report passed all validation checks\")\n",
    "    grammatical_errors: List[str] = Field(default_factory=list, description=\"List of grammatical errors found in the report\")\n",
    "    missing_sections: List[str] = Field(default_factory=list, description=\"Sections that are missing or incomplete\")\n",
    "    formatting_issues: List[str] = Field(default_factory=list, description=\"Formatting or style issues detected\")\n",
    "    data_inconsistencies: List[str] = Field(default_factory=list, description=\"Detected inconsistencies in data or facts\")\n",
    "    citation_issues: List[str] = Field(default_factory=list, description=\"Problems with citations or references\")\n",
    "    warnings: List[str] = Field(default_factory=list, description=\"Non-critical warnings or suggestions for improvement\")\n",
    "    checked_at: datetime = Field(default_factory=datetime.now, description=\"Timestamp when validation was performed\")\n",
    "    summary: Optional[str] = Field(default=None, description=\"Brief summary of the validation results\")\n",
    "\n",
    "class EvalReport(BaseModel):\n",
    "    grade: Literal['PASS', 'FAIL'] = Field(description='Final grade of the report based on your evaluation')\n",
    "    overall_score: Optional[float] = Field(default=None, description='Overall numeric score (0-100) reflecting the report quality')\n",
    "    reasons: List[str] = Field(description='Key reasons for the assigned grade, in bullet points')\n",
    "    recommendations: List[str] = Field(description='Actionable recommendations for improvement, in bullet points')\n",
    "    clarity: dict = Field(\n",
    "        description='Clarity evaluation details',\n",
    "        example={\n",
    "            \"score\": 1-5,\n",
    "            \"assessment\": \"Language is precise and unambiguous for a financial audience.\",\n",
    "            \"issues\": [\"Some jargon is not explained.\"],\n",
    "            \"suggestions\": [\"Define technical terms.\"]\n",
    "        }\n",
    "    )\n",
    "    objectivity: dict = Field(\n",
    "        description='Objectivity evaluation details',\n",
    "        example={\n",
    "            \"score\": 1-5,\n",
    "            \"assessment\": \"Tone is neutral and unbiased.\",\n",
    "            \"issues\": [],\n",
    "            \"suggestions\": []\n",
    "        }\n",
    "    )\n",
    "    completeness: dict = Field(\n",
    "        description='Completeness evaluation details',\n",
    "        example={\n",
    "            \"score\": 1-5,\n",
    "            \"assessment\": \"All key financial areas are addressed.\",\n",
    "            \"issues\": [\"Risk section is brief.\"],\n",
    "            \"suggestions\": [\"Expand risk analysis.\"]\n",
    "        }\n",
    "    )\n",
    "    logical_consistency: dict = Field(\n",
    "        description='Logical consistency evaluation details',\n",
    "        example={\n",
    "            \"score\": 1-5,\n",
    "            \"assessment\": \"Conclusions follow from evidence.\",\n",
    "            \"issues\": [],\n",
    "            \"suggestions\": []\n",
    "        }\n",
    "    )\n",
    "    professionalism: dict = Field(\n",
    "        description='Professionalism evaluation details',\n",
    "        example={\n",
    "            \"score\": 1-5,\n",
    "            \"assessment\": \"Report is well-formatted and suitable for executive review.\",\n",
    "            \"issues\": [\"Formatting is inconsistent.\"],\n",
    "            \"suggestions\": [\"Standardize section headings.\"]\n",
    "        }\n",
    "    )\n",
    "    reviewed_at: Optional[datetime] = Field(default_factory=datetime.now(), description='Timestamp of evaluation')\n",
    "    summary: str = Field(description='One-paragraph executive summary of the evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ccc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel,RunnableBranch,RunnableLambda,RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser,PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27611e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description='this tool is used to evaluate the report  and enhance it ')\n",
    "def evaluate_report(report: str):\n",
    "    \"\"\"\n",
    "    Evaluates and, if necessary, enhances the professional quality of a financial report.\n",
    "\n",
    "    This function uses two prompt templates:\n",
    "    1. Evaluation Prompt: Instructs a language model to act as a professional editor and harsh critic, evaluating the report on:\n",
    "        - Clarity: Is the language precise, unambiguous, and easy to understand for a financial audience?\n",
    "        - Objectivity: Is the tone neutral, unbiased, and free from unsupported opinions?\n",
    "        - Completeness: Does the analysis thoroughly address all key financial areas, including risks, trends, and recommendations?\n",
    "        - Logical Consistency: Do the conclusions and recommendations logically follow from the evidence and analysis presented?\n",
    "        - Professionalism: Is the report formatted and written in a manner suitable for executive or investor review?\n",
    "        The model must provide a concise, bullet-pointed evaluation summary and a final grade: \"PASS\" or \"FAIL\", with specific reasons for any shortcomings.\n",
    "\n",
    "    2. Revision Prompt: If the report is graded as \"FAIL\", the model is instructed to rewrite the report to ensure it is:\n",
    "        - Professional, clear, objective, and logically consistent\n",
    "        - Grammatically correct and free of ambiguity\n",
    "        - Comprehensive, retaining all original content and key points\n",
    "        - Improved in structure, flow, and tone for a financial audience\n",
    "        The model must return only the improved report, with no additional commentary.\n",
    "\n",
    "    Returns:\n",
    "        The evaluation summary and, if needed, an improved version of the report.\n",
    "    \"\"\"\n",
    "    eval_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a professional financial editor and a harsh critic. Your only job is to evaluate the professional quality of a financial report.\n",
    "\n",
    "Report to evaluate:\n",
    "{report}\n",
    "\n",
    "Judge the report on the following criteria:\n",
    "- Clarity: Is the language precise, unambiguous, and easy to understand for a financial audience?\n",
    "- Objectivity: Is the tone neutral, unbiased, and free from unsupported opinions?\n",
    "- Completeness: Does the analysis thoroughly address all key financial areas, including risks, trends, and recommendations?\n",
    "- Logical Consistency: Do the conclusions and recommendations logically follow from the evidence and analysis presented?\n",
    "- Professionalism: Is the report formatted and written in a manner suitable for executive or investor review?\n",
    "\n",
    "Provide a concise, bullet-pointed evaluation summary for each criterion. Then, give a final grade: \"PASS\" or \"FAIL\". If you grade \"FAIL\", clearly state the main reasons for failure.\n",
    "\"\"\",\n",
    "        input_variables=[\"report\"]\n",
    "    )\n",
    "    \n",
    "    revise_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a professional financial editor.\n",
    "The following report was graded as FAIL in evaluation.\n",
    "Your task is to thoroughly rewrite the report to ensure it meets the highest standards of professionalism, clarity, objectivity, and logical consistency for a financial audience.\n",
    "\n",
    "Instructions:\n",
    "- Carefully review the original report and retain all key facts, findings, and recommendations.\n",
    "- Improve the structure, flow, and tone to be suitable for executive or investor review.\n",
    "- Ensure the language is precise, unambiguous, and free of grammatical errors.\n",
    "- Remove any unsupported opinions, ambiguous statements, or logical inconsistencies.\n",
    "- Address any gaps in completeness, ensuring all relevant financial areas (risks, trends, recommendations) are covered.\n",
    "- Do not omit any important content from the original report.\n",
    "- Return only the fully improved and revised report, with no additional commentary or explanation.\n",
    "\n",
    "Report:\n",
    "{report}\n",
    "\"\"\",\n",
    "        input_variables=[\"report\"]\n",
    "    )\n",
    "\n",
    "    eval_chain = eval_prompt | model | StrOutputParser()\n",
    "    revise_chain = revise_prompt | model | StrOutputParser()\n",
    "\n",
    "    def route(output: str):\n",
    "        small = output.lower().strip()\n",
    "        if any(i in small for i in ['fail', 'needs improvement', 'needs revision']):\n",
    "            return \"revise\"\n",
    "        else:\n",
    "            return 'pass'\n",
    "\n",
    "    conditional_branch = RunnableBranch(\n",
    "        (lambda x: route(x['evaluation_result']) == 'revise', revise_chain),\n",
    "        RunnablePassthrough()\n",
    "    )\n",
    "\n",
    "    full_chain = {\"report\": RunnablePassthrough(), \"evaluation_result\": eval_chain} | conditional_branch\n",
    "    return full_chain.invoke(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checker=create_react_agent(\n",
    "    model=model,\n",
    "    tools=[ query_data, search_web, handoff_to_insider_agent_tool,get_current_markettrends,get_market_status,handoff_to_librarian],\n",
    "    response_format=ComprehensiveFactCheck,\n",
    "    name='fact_checker',\n",
    "    prompt='''\n",
    "You are the Fact Checker for the Heimdall system. Your primary responsibility is to verify the accuracy and reliability of information provided by other agents or found in external sources.\n",
    "\n",
    "**Your Workflow:**\n",
    "1. When given a claim, statement, or report, you must use the available tools to independently verify the facts.\n",
    "    - Use `query_data` to check the Corporate Library for relevant documents or evidence.\n",
    "    - Use `search_web` to find up-to-date information from reputable online sources, such as news articles, press releases, or official company websites.\n",
    "    - Use `get_market_status` to confirm the current status of the financial markets if relevant to the claim.\n",
    "2. For each fact you check, clearly state whether it is supported, contradicted, or unverified based on the evidence you find.\n",
    "3. If you find conflicting information, present both sides and explain the discrepancy.\n",
    "4. you are allowed to handover the claim to the librarian for further analysis to fact check the data.\n",
    "4. If you cannot verify a claim, state explicitly that it could not be verified and suggest possible next steps or sources for further investigation.\n",
    "\n",
    "**Output Format:**\n",
    "- For each claim or statement, provide:\n",
    "    - The original claim.\n",
    "    - The sources you checked (tool and result).\n",
    "    - Your conclusion (Supported / Contradicted / Unverified).\n",
    "    - A brief explanation of your reasoning.\n",
    "\n",
    "Be thorough, impartial, and concise. Do not speculate or provide opinionsâ€”only report on what you can verify with the available tools and data.\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "evaluator_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[ evaluate_report],\n",
    "    response_format=EvalReport,\n",
    "    name='evaluator',\n",
    "    prompt=\"\"\"\n",
    "You are the Evaluator for the Heimdall system. Your primary responsibility is to critically assess the quality, accuracy, and completeness of the reports and analyses produced by other agents.\n",
    "\n",
    "**Your Workflow:**\n",
    "1. Carefully review the provided report or analysis in its entirety.\n",
    "2. Check for factual accuracy, logical consistency, and completeness of the information.\n",
    "3. Use the available tools to independently verify any claims, data points, or conclusions that seem questionable or require further evidence.\n",
    "       - Use `evaluate_report` to perform a structured evaluation of the report's content.\n",
    "4. For each major claim or conclusion in the report, explicitly state whether it is supported, contradicted, or unverified based on the evidence you find.\n",
    "5. Identify any errors, omissions, unsupported assertions, or logical inconsistencies. If you find conflicting information, present both sides and explain the discrepancy.\n",
    "6. Provide constructive feedback, highlighting both strengths and weaknesses, and suggest specific improvements if needed.\n",
    "7. If you cannot verify a claim, state explicitly that it could not be verified and suggest possible next steps or sources for further investigation.\n",
    "\n",
    "**Output Format:**\n",
    "- For each claim or statement, provide:\n",
    "    - The original claim or section.\n",
    "    - The sources you checked (tool and result).\n",
    "    - Your conclusion (Supported / Contradicted / Unverified).\n",
    "    - A brief explanation of your reasoning.\n",
    "- At the end, provide a summary of your evaluation, including:\n",
    "    - Key strengths of the report.\n",
    "    - Any issues found (with evidence or reasoning).\n",
    "    - Suggestions for improvement.\n",
    "    - A final verdict: Acceptable / Needs Revision / Unacceptable.\n",
    "\n",
    "Be objective, thorough, and concise. Do not add new analysisâ€”focus on evaluating what is presented. Do not speculate or provide opinionsâ€”only report on what you can verify with the available tools and data.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "validator_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[evaluate_report, search_web],\n",
    "    response_format=ValidationReport,\n",
    "    name='validator',\n",
    "    prompt=\"\"\"\n",
    "You are the Validator Agent, an expert in investment report validation and quality assurance. Your primary responsibility is to deliver a final, authoritative judgment on the quality and reliability of the investment report, based on the outputs of the Fact Checker and Evaluator agents.\n",
    "\n",
    "**Your Workflow:**\n",
    "1. Carefully review the original investment report, the Fact Checkerâ€™s findings, and the Evaluatorâ€™s assessment.\n",
    "2. Cross-examine the evidence, conclusions, and recommendations from both agents. Pay special attention to any discrepancies, contradictions, or unresolved issues.\n",
    "3. Use your tools (`evaluate_report`, `search_web`) to independently verify any remaining uncertainties or to resolve conflicts between the Fact Checker and Evaluator.\n",
    "4. Assess the overall accuracy, completeness, and trustworthiness of the report, considering all available evidence and expert analyses.\n",
    "\n",
    "**Output Format:**\n",
    "- For each major claim or section in the report:\n",
    "    - Summarize the Fact Checkerâ€™s and Evaluatorâ€™s conclusions.\n",
    "    - State your own final validation (Validated / Not Validated / Needs Further Review).\n",
    "    - Provide a brief justification for your decision, referencing specific findings or evidence.\n",
    "- At the end, provide a clear, concise final verdict on the report as a whole:\n",
    "    - Acceptable: The report is accurate, complete, and reliable.\n",
    "    - Needs Revision: The report has issues that must be addressed before acceptance.\n",
    "    - Unacceptable: The report is fundamentally flawed or unreliable.\n",
    "\n",
    "Be impartial, thorough, and precise. Do not simply repeat previous findingsâ€”synthesize all available information and make a definitive, well-justified decision. If you cannot validate a claim, clearly state why and suggest what further evidence would be required.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "validation_supervisor = create_supervisor(\n",
    "    model=model,\n",
    "    agents=[fact_checker, evaluator_agent, validator_agent],\n",
    "    prompt='''\n",
    "You are the Head of Quality Assurance. You have been given a draft investment report.\n",
    "\n",
    "Your workflow:\n",
    "1. Send the report to all three agents: the Fact Checker, the Evaluator, and the Validator.\n",
    "2. Collect the outputs from all three agents.\n",
    "3. Carefully review and synthesize their findings into a single, comprehensive validation report. This report should:\n",
    "    - Summarize the key findings, agreements, and disagreements among the agents.\n",
    "    - Highlight any unresolved issues or uncertainties.\n",
    "    - Provide a clear, well-justified final verdict on the report's quality and reliability, referencing the agents' analyses.\n",
    "4. Respond with your comprehensive validation report, followed by the single word \"FINISH\".\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as your ONLY state definition\n",
    "class HeimdallState(TypedDict):\n",
    "    ticker: str\n",
    "    mission_plan: Optional[str]\n",
    "    # This will store the final reports from each manager\n",
    "    financial_report: Optional[str]\n",
    "    news_report: Optional[str]\n",
    "    technical_report: Optional[str]\n",
    "    # The final, synthesized report\n",
    "    research_report:Optional[str]\n",
    "    risk_report:Optional[str]\n",
    "    final_report: Optional[str]\n",
    "    validation_report:Optional[str]\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43608b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_agent(agent,agent_name:str,state:HeimdallState,key_to_update:str):\n",
    "    result=agent.invoke(state['messages'])\n",
    "    return {key_to_update:result.content, \"messages\": state[\"messages\"] + [AIMessage(content=str(result), name=agent_name)]}\n",
    "\n",
    "def research_supervisor(state: HeimdallState):\n",
    "    return run_agent(supervisor_graph,'supervisor',state,'research_report')\n",
    "\n",
    "def risk_agent(state: HeimdallState):\n",
    "    return run_agent(risk_supervisor,'risk_analyst',state,'risk_report')\n",
    "\n",
    "def validator_supervisor(state: HeimdallState):\n",
    "    return run_agent(validation_supervisor,'validator',state,'validation_report')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas._libs.writers import word_len\n",
    "\n",
    "\n",
    "workflow = StateGraph(HeimdallState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)  \n",
    "workflow.add_node(\"research_supervisor\", research_supervisor)  # Use the compiled supervisor\n",
    "workflow.add_node(\"investment_strategist\", investment_strategist_node)\n",
    "workflow.add_node('risk_analyst_supervisor',risk_agent)\n",
    "workflow.add_node(\"validator_supervisor\", validator_supervisor)\n",
    "\n",
    "# Set up the flow correctly\n",
    "workflow.set_entry_point(\"orchestrator\")  # Start with orchestrator\n",
    "workflow.add_edge(\"orchestrator\", \"research_supervisor\")  # Orchestrator â†’ Supervisor  \n",
    "workflow.add_edge(\"research_supervisor\", \"investment_strategist\") \n",
    "workflow.add_edge('investment_strategist','validator_supervisor') # Supervisor â†’ Final Report\n",
    "workflow.add_edge(\"validator_supervisor\", END)  # End\n",
    "workflow.add_edge('orchestrator','risk_analyst_supervisor')\n",
    "workflow.add_edge('risk_analyst_supervisor','investment_strategist')# Final Report â†’ Joiner\n",
    "#\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAITCAIAAADkUq7nAAAQAElEQVR4nOzdBXwTZx8H8Oci9RYoBQotUIp7cRgbLgOGuw4bMHgZDBjuMpyxIWPIYDgMhzFkyLDhFLfS4k5LXSL3/pMrIW2TUL9L8/vCJ5/k7nJ3uT73u+d57nJR8DzPAADAFAUDAAAzEJEAAGYhIgEAzEJEAgCYhYgEADALEQkAYBYiEiyJCI7zP/X+7ZPY2Gheq2FxcVpOxnitbhQno3+MZ0yr0V03xnEcz/M0luOZlmcyGafV6obTE56GabWGIRy9i2dyGafR8oaBwpSMi59bguFymVajNawSLZXXj5IrZBq1lt7CEl63prTjaDXsHWS58tv71c7mmsOeAaQWh+siIam4OM3ORc/ePY/TapnSnrNz4JT2cpmcU8fwQsAxXVTpokkXUEJ86aOKBmp1iUi5xsVHp5yG60LNkK3xoUbDNTSW4zXxJVCXuJyW13DCu3hN/MoYTxO/XCGjFYxXs6QRqbBnFK+qGG1stFat0k3v4a1s9W0+ewclA0ghRCQk9se0oPBgjaOrrERll5otcjMrd2b36zuXw6PCeJccsp4TfRlASiAi4aPDG17evRjhnlfZZWRBluVsnP0w+KW6eGWXhl09GUDyICIh3vqZDyPDNF1H5XfJbseyqOhw9bqZDx2d5N3HF2IAyYCIBJ3dy56Ghai7j/FhNmD9zEAnN2WbQfkZwKcgIoGtmRIkV3Ldx/owm0F1SXUs32sy6pLwCTIGtm3z/Me2lo+E6stKO27LvEcMwCJEpE27cuxdyMs4W8tHQbexPsGvVZeOvmMA5iEibdrZ/SE1vnJntoo++/m/QxiAeYhI27Vv5XOFkvOrbbsR6VfLXWkv2/PbMwZgBiLSdj2+G1WxXnZm2yrUy/7sQTQDMAMRaaMuHw/mGKvUICezbZXquXOMu3w0mAGYgoi0UbfOhLm6Z/ZNTLZu3Tpp0iSWcg0bNnz2LKOaw245FTfPhjEAUxCRNioyTF2gpCPLXLdu3WIp9+LFi5CQDDypkr+4Y1S4hgGYgpuh2Si1ihWr5MYyxsOHD5ctW3bp0iWe58uVK9ejRw8/P79+/fpdvnyZxv7111/r168vUaLEli1bTp48eePGDXt7+4oVKw4aNMjb25smGDlypFwuz5s379q1a/v37//bb7/RwJYtW9auXXv+/PksvZWs6nrtFGqRYBpqkbYo+E0cPXrmz5BaZFxcHKUhZdyiRYt+/fVXhULx/fffx8TELF++vEyZMs2aNbt48SLlo7+//9y5c8uXLz9v3rwpU6YEBwePHz9emINSqQzQW7BgQbt27RYuXEgDd+/enRH5SDzyOVK37JsXOGkDJqAWaYtCXsRyGXZwfPToEeVd586dKQfp5axZs6jyqFarE01WtmxZ6posUKAAZSi9VKlUlKShoaHZsmXjOO758+fr1q1zcHBgmYIiMvyNOldeBpAIItIW8bp7dXMsY1Dq5ciRY/LkyU2bNq1UqRLVEytXrpx0MqpmPn36lCqG1NCOjIwUBlK2UkTSk0KFCmVaPjL9PXl5XssAkkBD2xa5eSgMP3uQ7qhjccWKFZ9//vnGjRv79OnTqlWr/fv3J53s33//HTZsWKlSpWjiCxcuLF68ONFMWCbSaplTNtyTHExARNqi3N6OVGd6/zajet98fHyGDh26b98+6kwsUqTIxIkT79y5k2ianTt30jkcOkVTrFgxalmHh4czkUSFq6kamdfHiQEkgYi0UTIFu30ukmUAOp29Z88eekIt5Vq1as2ePZt6G2/fvp1oMup2zJ37468+HD16lInk2qn3MjkDMAkRaaMcXeRBNzMkIin7pk6dSqehnzx5QqduVq9eTedqqEeSRuXPn596HqlZTX2OVHk8e/Ysnd2msRs2bBDe++LFi6QzpDopPR4+fJjeyzJA4LVwO8eM6pkFa4eItFFF/JxC36pZBqA0HDt27N9//926deu2bdteuXJl2bJlvr6639Vq06YNtampcX3//v2BAwd+9tln1B1Zo0aNly9fTpkyhfolv/vuuwMHDiSaobe3d/PmzWkmixYtYhkg+KWmcHlnBmAK7jpuuxZ/H/Dl13mK+LkyG3bfP/zQ2leDFhRhAKagFmm7cnnb/bv9DbNtJ3e8zZk3y/6cGaQdrou0XR2HF6CK5POg6HyFTH/NpkePHo8fP046XKPRUONDuOQ7qV27dmXPniH3WPP396cT5SZH0SrJZDJqxZsce+TIEbncxBmZ50FRURGa3lPxCzZgFhraNu3whhdBN6P6/VjY5NiIiAhzxYPOsZiLSFfXDGy5p+7aIHOr9NvogEKlnRt1x7dqwCxEpK1bPTkom4eizf9s7hdTdyx6GvpOhR9BBMvQF2nrKCPePI39+4/nzJYcWvf8zdMY5CN8EmqRoPP75ECPvMoW/W2iLrlv1bPXj2J6Ty3MAD4FEQnxVox7YO8o6zE+i1esNswMigzT9puJfIRkQUTCR5vmPHr3SlXML2uewaBzU/evRLp7KjuNKMgAkgcRCQncu/z+n01vtWqWp6Bd/S553HNn6h13MkLwq9hjW1+9CIpTKLjaHTxKVs7GAJINEQkmXDry9uI/71UxjJMxJ1eZSw6lk7Pc3oGLU5u+8JDjmFE54nUDPgxJOMrwBt1UwijLUxoN5PVvMzNDIwoFi4vRxkRqIkLV0eEarYY+grxcLbdK9W395x4hFRCRYMm5v98+vR8d/l6tUfFaLVPHJbe0fAwyfRqaoyt+3If7+5qc8sPA+IBMRkQq7XUTKZScWw6FVzGnao2RjJB6iEgQ09KlS+3t7fv06cMAJAnXRYKYLHxLB0AKUDpBTIhIkDiUThATIhIkDqUTxKRSqZRK/K4WSBciEsSEWiRIHEoniAkRCRKH0gliQkSCxKF0gpjQFwkSh4gEMaEWCRKH0gliQkSCxKF0gpgQkSBxKJ0gJkQkSBxKJ4gJp2tA4hCRICbUIkHiUDpBTIhIkDiUThATIhIkDqUTxISIBIlD6QQxISJB4lA6QUyISJA4lE4QEyISJA6lE8SEiASJQ+kEMeHScZA4RCSICbVIkDiUThBT/vz55XI5A5Aq/I42iOnZs2fU1mYAUoWIBDFRK5va2gxAqtDQBjEhIkHiEJEgJkQkSBwiEsSEiASJQ0SCmBCRIHGISBATIhIkDhEJYkJEgsQhIkFMiEiQOEQkiAkRCRKHiAQxISJB4hCRICZEJEgcIhLEhIgEiUNEgpgQkSBxiEgQEyISJA4RCWJCRILEISJBTIhIkDiO53kGkLnq168fHBwsk8mE4kePHMeVKFFi48aNDEBKcEtdEEHNmjU5PZmeXC53cHDo3r07A5AYRCSI4Ouvv86fP7/xkIIFCzZp0oQBSAwiEkRQuHBhqkgaXtrZ2bVv354BSA8iEsTRrVu3fPnyCc+9vLxatWrFAKQHEQnioHysXbs205/UbtGiBfVIMgDpwRntrOz2hdCn96NUcVzSURzjGccZ/vicMAnP+A8vjUclKiMyjmn5j8MTTKx7mmRxdMJaxiUtaLFxsZcuXaIn1atWlcl115/pJkoypW41dWe8hTkl+SCG1fiwaBnHafWDZLoPmfAtHGPGH5lnfOLNkmCI0o73KuxYqlp2BrYKEZk1hQfHbZr3WKNmCqVMFWviT6yLD/qvjX9JESYEhonU0z3n2Yfg0yULhZZWF1pC4eFkH+dDBYrp4+xDbOkSh4YxudE0RoSMkss4rdGa0MyNpxGG6JdrtMJJAtqwGjLd3OJXzPCJEr1LeE6z1CaKY1mC9bRz4FRxWrmcdRhWIHsuOwa2BxGZBYWFxK2f8bhkVdfKjfMwSLOLR17e/i+iy6gC2T2QkjYHEZkFLf0hoGEPT88CLgzSyduX0QdWPvt2bhEGNgZ95FnNzl+f2DvLkI/py8PT0d6Z27HkEQMbg4jMakJeqXJ6OjBIbx55Hd+/0jCwMbiNRVajiublchz50p+cTnypGNgaRGRWQ6eG0b2cEWjDalGJtD2ISIBk4XmGg48NQkQCJIvuOkqOga1BRGY1whXRkO54HpVIW4SIzHI4howESC+IyKyGx+kagPSDiMxqUIPMMBzHcPCxOYjIrAY7cQbhOF5/YwywLYhIgGTBscc2ISIBkkW4XyUDG4OIzGpw0U8GofNgWiSk7UFEZjU8j6pOhqB+SBmuHbc96H7OgjL/xGv7jk1WrlrCsjT9peM4+tgcRGRWo/uZLCuv7EyZOnr/37tZyrVu2/D5i2csYwi/SMHAxiAis5oscKefu3dvsZR7+fLF+/chLMPgNha2CX2RWU0qTtdERUUtWPijv//F8PAwn4K+TZq0bNWyPQ0PDAzo802nmTMWzlswPXv2HCuXb9JoNH9u2/DH2uU0tlTJsj2/7l+2rJ8wE4VCuWPnlmW/LbSzsytTxm/M6KnZ3LLRcLVaver3pWfPnXr9+iUNb92yQ/XqnwtvOXvu9JYta+/cvenu7lGmTPl+fQfnzOlRt35lGjV33rRfl/20d/fxSZNHyuXyPHnybt6ydsrkObW+qEdLOXv25O3bN+zs7cuXq9inzyCvfN5X/C8OGz6A3ti1W8uaNWtPnzqfnq9dt/LgoX1v377OndvTr3yl74eOkclkxh+qTOnykyfNTuZW4vDNTpuEWmSWk/I9efTY754/fzpt6vytm/fXqlX/519m375zk4YrlUp6XLt+ZccO3YcPG0/Pl69YtHv3n1OnzBs/dkauXHlGjRn8+PFDYSb/nvgnMjJi9qxFP4yYeOOG/+rVvwrDf1k0Z9v2ja1bddy4YW/tWvUnTRn574kjNPze/Ttjxg6pUKHKmt+3fTd45IMH92bPmUzDD+w/TY8/jJhA+SisQ2BQAP2fMW1BubIVrl/3X7R4bunS5adOnTd61JSQkOAZP+pWrIJfZUo9erJh/W4hH1evWbZr99Zv+w/d9ufBPr0HHv/3MIV7og/Vo/s3LNn0tUgGtga1yCxHtyenICOpKke58/vKLYUKFaaXXbv0Onf+NNUTZ/34s/Db1VUqV2/fris9CQ0L3frn+qFDRtMQelmtWs2oqMh3wW8LFPChl05Ozt279RHmefrMv9euX6EnsbGxVI/r0rlni+Zt6WXTJi1v3Li6dt0Kysob1/0dHBy6de1NNbs8eTxLFC9FOZh09WgdXr58vmzpOpqYXrq6uq1etdXbu4BCoSu6apVq7PjvacWEGqtBeET4ps1/fDvg+88/r0Mv69RuEBh4f/2GVW1ad0r0oQAsQ0RmNfqLflJQ2wkKCqD0EfJRUKxoySNHDxi/FJ48DHpAjyVKlBZeUkhNnTLXMFnZMn6G59ncssfFxtKTe/dux8XFValcwzCKGrx/H9hDoVamrF9MTMyYcUMrV6pWo0Ytb6/8VBM0uYYFCxQS8pFQo5sqvEuWzr9950ZkZKQw8H1IcKKIfPLkkUqlKlmyzMdPUaxkRETEs2dPhGw1fKjkw/0ibRMiMqtJaV/ku3dv1pPqCgAAEABJREFUHRwcjYc4OTlFR0cZXlKXn/AkIiKcHh3sTf92mBA9H9aBM37L4CF9Ek0cEvyuWNESs2b+cuLEEWq8L/31p0oVq1LPJvVIJp2zYQXI6dP/jp84nKq6/fsNKVy46MVL50aO+l/StwQHv020qo6OTvRIn4vqoYnmmUy4X6RtQkRmNSm9dNzZ2TkmJtp4SGRUpEfOXKam1P3wLDWuWbLl9NDNZ/iwcV5e+Y2H0/kTeqxW9TP636vngEuXzm3fsWnsuKE7th+2PMN9+3fSCaK+fQYJL4UINreq0UafS1htOi+kUsWxVEEV0jbhdE1Ww8lStjMXL1aKGrz3A+4ahtDJYh+jdrdBkSLFqap49dpl4SXP86PHDjl4cJ+FmXt7FbDX19eoES38pzPm1HCmiqq//6Vz58/QKA+PXI0bfzVo4HDqQHz56gWzKCwsNJdHbsPLkyePmpyscOFi1CS/efOq8YdydXHNlSs3SwOkpA1CRGY1HJ+ylnbVqp/ly+e9YMGMO3dvBQe/W/X7UkqTju27J53SxcWlYYOmdEabOhOv+F+kM8tU+zPu70uKopCaz3R+hs4IUackncseMXLgwp9n0agbN69OnjJy774d79+H3Lp9Y8fOzZSVnnnyUqRSkF28eJYWoVarE82wSOFiFz6MEs5QEyFY8+vPGh0/fpjm5ubqRqu6fsPvZ86cCAsPO3Tor527trRr11UmS32BR0PbNqGhndXo2tnaFExPFcPpU+cv+23hwEFf29nZ+foWnTZ1nuFqx0SGfDeKAm7+ghkajYbSaurkucLpbAs6dexBdbqNm9dcvnye2r+lS5UbPlx3mU6H9t0oHBcvmbfgpx9pufXqNv5pwXKhQ7Nrl96r1yw7f+HMpo2Jq6i9ew+kJvP4CcOio6Pp9PToUVNevHg2esx348ZOb1D/yy8bN6c3lild/qcFv1G1lAJx2oyxFKZ0DOjSuVfnTl8zgBTi8LXTLGbZqAdehZ3rdPRkkK6Ob3357H7kgDmFGdgS1CKzGt1v1zBIf7qtivqE7UFEZjW4fC/j8PgGou1BRGY1OKuQQehMDydDRNocRGRWgypkBtHdQgm3Hbc9iMgsBw1tgPSDiMxy0NDOGOjktU2IyCwIO3LG4LFpbRAiMqvBz3tlEJ7HRcS2CBGZ1cjkHIcGIUA6QURmNXTWFfXIjKDvi8Sxx+YgIrMgDgmZAfAjsbYJEZnloKIDkH4QkVkNvqMNkI4QkVmNwk4mVyIk059CyezsUUW3OYjIrMbBmYUHp/K3B8CC929jFPY49tgc3HU8qylW0fX9GzWD9Bb+Vl28cjYGNgYRmdVU+9LD0YnbOv8Bg/Sz7ecH9k6y6k08GNgYfGEgCwoODt78S4A81r1ASRfPgs5KO9MHQu7DV+qSlgCOi/+id6Lv3JmcOPmz5oUbEfGGpVDp40zPNsmg5E3DG27pyOuP/7yZNUrmdwnjVPzzgNAXgdHZPFio87H27dtnz56dgS1BRGYp586d27Ztm7+/f7t27Xwcmz2+F6uO4zUqlm4M2ZkuzAdV0uUkZ0i6kyuY3I75lHCu3yX3ihUr/vzzzypVqlBQVqpUiYFtQERmBTExMZSMtAN7eXlRONarV49Bxjh8+DBt5/fv37fXY5DVISKt27Vr1ygcjxw5QslIe6y3tzeDjPfgwQMKStrywmYvXBi/+ZVlISKt1fbt22kXdXBwoL20WbNmDMTwpx51UFJQNmzYkEGWg4i0MgEBAbRPUj62adOGwrFYsWIMxHbp0iX6o1y4cEFofefMmZNBVoGItBr79++namNkZCTthBSODCSGOiiFSqWfnx/9jejEDgPrh4iUuqdPn1IyUrWxTp06lIzly5dnIG3UNUxB+ebNmw4dOtCfTC6XM7BaiEjpOn78OO1pFJG0m7Vt29bJyYmB9Xj48OHWrVvp8NaqVSuqVBYtWpSBFUJESk5wcPA2vbJly9KuVb16dQbWjFoAdKhzdnamSmXjxo0ZWBVEpIScO3eO9qWrV6+200Ovf1bi7+9PlcozZ87QYY+yMleuXAysASJSfNHR0UK10cvLi/afunXrMsiiwsPD6ShIWVmqVKmOHTtWq1aNgbQhIsUkXPh99OhRodqIC79tx7///rtly5bnz58LlUqlUslAkhCR4hD6pxwdHXHhty178uSJUKls2rQpBWWJEiUYSAwiMlPdv3+fdokdO3a0adMGZznBYPfu3RSUVJekUoFDpqQgIjOJcOF3VFQU7QNt27ZlAElcv36djqDHjx+ntgVVKj09PRmIDRGZsYQLvwmdhMGF35AckZGRVGCoUkmNDDqg1qxZk4F4EJEZ5dixY1QjePbsmXAqhrodGUBKnDx5kopQUFAQ1SgpKx0cHBhkOkRkOnv37p1wD55y5cpRscZVHZBGdNabapSUlQ0bNqQSVbp0aQaZCBGZboQLv69du0ZdjbjwG9Ld3r17qYDRDkuVyubNmzPIFIjItMKF35CZbt26RZXKw4cPCzdeo1LHICMhIlPv6tWrlIzU54gLvyGTxcTECDdeK1iwIFUqv/jiCwYZAxGZGsKF305OTpSMTZs2ZQAiOXPmDFUq79+/L1QqnZ2dGaQrRGQK4MJvkKaXL18KlcratWtTpbJs2bIM0gkiMln++usvalNTtyMu/AYp279/P1UqVSoVFdRWrVoxSDNEpCWhoaGrV6+mcKxXrx61qcuVK8cAJO/OnTtUo6TjOgVlnz59smfPziC1EJFmqdVqKl4NGjTAhd9gjaguSUF56NCh5cuX29nZMUgVRKRZWq22WrVqFy5cYABWq27durt373Zzc2OQKjIGZshkuo1DQckArJZCoaD2EIPUQkRaguIF1g5lOI0QkZageIG1k8vlGo2GQWopGJiHiARrhzKcRohIS1C8wNqhDKcRItISFC+wdijDaYSItATFC6wdynAaISItQfECa4cynEaISEtQvMDa4Yx2GiEiLUFEgrVDGU4jRKQlKF5g7VCG0wgRaQmKF1g7lOE0QkRaguIF1g5lOI0QkZageIG1QxlOI0SkJSheYO1wRjuNEJGWICLB2qEMpxFuqWtChQoV6JHTo+1Dj3Qc9vHx2bVrFwOwBlSGqdwaXgol2cvLa+/evQxSAjdDM6Fq1apUpGQymeHRzs6ua9euDMBK1K5dWyi9AuF5mzZtGKQQItKEnj175sqVy3iIt7c3fk8OrEifPn3c3d2Nh1AZxo93pgIi0oQaNWqUKFHC8JKOwJSPSqWSAViJsmXLli9f3nhIo0aN8As2qYCINK13796Gg3C+fPnQQgGr8+233+bOnVt47unpiSpk6iAiTaMjsOFXs5s0aeLi4sIArErhwoWpV114XqtWrTx58jBIuWRd9BN0O0yrkgvPeU73L/45vWKc/gkznDwzDEwwmNMPNj+HFKEzdfrz8B/nb3jG6Z9bZLyySV9+1KJ+v1dBnFKhrFqmxYNrkUmnFlbDxPs/fFjDyugnTDqV7mR5giGmJjPz0Uyvtu79SQab28icfiZJNxfPNHZ2XIESrsx6PLwVplHLLU6SYIslLScmN2gyipN+siQFMplzSDRW/9JsgRQWpGUfd59PrBVjX9bq+ehWLM9ra1VqbyjDepaWEj8Fl5wFxc/H3MfUvz9BqeY+vCfhBzdR8k0tLDVxYZZMXbhMtk9O9YmLfjbPDQp+raGV0ny4surTm/YD4931k+9KMLGp/dywwoZtmyCXLb0l0ZISrMon3yhc9GPu7aYGpGATJfJhT0ufuaVyeXoyuW65eQrYtfuuAJO2TXOCQqiIch+LqGmf2o4mS4L5LZSaRaSLFO1K5iUz/K1T8v4QnFw3lWtOefcxhSxNZiEi188OjIvSftE6j2cha6pQQLp4ei/s5K7X7rkV7Yb4MKlaOz1Qw/O12+bN5eXEAFLo/Zvof7e+jI7SfDO9iLlpzEbkmimBcjvWaqAvAxu27ecAuVzWY5wUi8GqiQ+cs8ma9S3EANLg+NanzwNj+s80nZKmT9fc/C8kJlKLfIR2Q4pEhGif3Y9gEnPxn7fqOIZ8hLSr08FbxnHHtr0yOdZ0RN4+H+bggpPdoGPvyC4fC2ESc/9KhKMbiiikD+qRfHzHdD3AdCGLjeHkCtzhAnTkdsqocCY1qjhOgSIK6cTe0U4TZ/qKCNOFTB2n5bUZf3IOrAEVBrVScoVBHavlOBRRSB8aDR8XqzU5CsdhAACzEJEAYOtkMk4mN90oMd0XqW/C4D6SAGATdGGnNZ14pmuR+osl0dED0sVxKKCQbng6+WJmlOlapP4WnAyAyCQZRsK34wEymoW+SGQk6GglGUa6ozgDSB/6H2ExPcpCQxtAurRalFFIR2ZLk7mIZCiAAGAzOHMhiYt+wCrhdA2kJ/P3q0REwidQr59czqQIGQnpRWa2MJmOSE6GyyIhHvX6aTRMatAXBOlJa7Ywmbl0nOe0Wav8zfhx/OAhfZiVmzR55PAR3zJgusN+Gk9pf3JjBgYG1K1f+dq1K0w823dsbtCoGrMl4hRy3a9QmB5juhZJZwvR1SNBtWrVV6niGDB9GU3bUTzLb8ydu7beuXtzzKgpzKqI83cx/zs96Iu0JvXrNWaQTrL8xrx79xazQuL8XcxXCNMtIlu2rt+jW98Tp45Sw2T3rqNurm4HDu7ds3d7UFBAoUJF6tVt1LZNZ6FpFB4RvnrNsnNnT4W8Dy5erFSDBk2aNW0lzMTcWyIiIv7ctv78hf8ePnyQ093js89q9+71rYODg8nl/vffyZ8XzX7z5nWRwsVaterQ5MsWwsyVCqW//6UZM8e/fx9CowYPHlmqZBnLH8rcqo4ZN5QeZ85YKEx28OC+WXMm/7X3hJOT01ctanfp3ItK54mTR52dncuWrTB2zDRXF92P/6jV6lW/Lz177tTr1y/LlPFr3bJD9eqfM32Drs83nWhu8xZMz549R/Vqn+/ctWXXjiNKpVKY/+Yta+mNu3cenT1nckRE+Px5v9LAs+dOb9mylqoJ7u4eZcqU79d3cM6cHjQ8KipqwcIf/f0vhoeH+RT0bdKkZauW7ZMuZeXyTcyaUblI6cXjiYrK/PnTP7kxja1dt3LjptU/LVheskRpC0uh4nf02MFr16+EhYWWLFGme/e+Ffwq0/CgoAe9+3ZcuuSPjRtXnzp9PFeu3HXrNOr3zWC5/lzYjp1bzp49efv2DTt7+/LlKvbpM8grn7fxbId8/429nf2c2YsNQyZMHPEu+O3SxWseP35IpdT/6iWqV5cuXa5Thx5ly/oNHdbv6tXLNNmhQ3/9tmx9saIlzK1wKgr5uAnDaG8qWLAQlUytVutbqMgPIyYWKVJMmNLcXmy8/du167J//65PFnKTH83w5zh4aN/bt69z5/b0K1/p+6FjZDKZcSHPkyfvkkWrWfLourbNfAMx3b6ASB913/6dRYoUnztniZOj0z9HDsyeM4X+MBvX7+nbZ9C27RsXL9hyYtUAABAASURBVJ0vTDlnzpRbN68NHTpmze/bSpYs89PCmTdvXqPhFt6yY+fmjZvWdOzQ/ccZC/v3H3L838N/rF1ucrlUQCdMGtGn96BZM3/5/PO6c+ZOpdkKU756/XLP3m0UWDQqThU3d97UTzbVzK2qBXK54s9tG776qs3Rfy7MmbWY/saLFs8VRv2yaA59qNatOm7csLd2rfqTpoz898QR4SPQ49r1K+kDDh82nvYcirnz588Y5nny1LEa1b+gomkYcu/+nTFjh1SoUIVW7LvBIx88uEcFSxg1eux3z58/nTZ1/tbN+6nN8vMvs2/fuZl0KSzZqCzIZJLrdaE/XUovHk9UVAzDLWxMAypFtK9OGPej5XyMiYmhY3BsbOzoUVOorBYo4DNu/PfBwe/Yh+0/f8H0+vW/PHTgv3Fjpm/9c/2x44dp4PXr/lRISpcuP3XqPHpjSEgwdZ0nmnPTL1teunxemJWwIDrWNmrYLC4ujtKQcnb2rEXz5/6qkCtoiTR2IUV5yTKNGjU7duSihXxkqSrktJQr/hfpyYH9p/9Ys909p8f4icM0+pN6FvZi4+3fsH6TTxZycx+NRtHfYtfurd/2H7rtz4N9eg+kQKCdjiUs5PSnZOnBzKXjuo6elO0VlKlubtkGDxohvKRDRLlyFYYOGU3Pc+Rw7/X1gDnzpnbr0pueX712uVPHHlUqV6dRdBStXbtBNrfslt/SoX03yhQ6agkzv3Hj6vkLZ/r3+y7pcmnb1fqiXsMGTeg5LSIyMiIqKv7ng9+8ebXs13VCha5N607z5k+n43y2bNktfChzq2oZVVGFt5QqVbZli3YrVy35YfgEOtjSQa9L554tmrelUU2btKRPsXbdCvpcwuGI3tK+XVdhDvnyeVOJqVmzNj1/9+7trVvXJ02cZbyIG9f9qRLdrWtvOnLmyeNZonipwKAApq8N0f72+8othQoVppddu/Q6d/40HU5m/fhz0qUkE5UFbZY4eZeoqBiY25gG1Pig0KTyJvxFLKD5rFy+2dHRUShXVIvcvWfb9Rv+9FcWJqhdq0Gd2g3oSfnyFfPl9bp373aD+l9SOVm9aqu3dwHhPupqlWrs+O9DqXC6ffyV57p1Gy1eOo/qp+3adqGXVA+lx3r1Gj958ogilWpqQg5SOaFCS+0VlmypK+RxcbHdu/WlTUqfolfPAf0HdKOC5+dXycJenGj7f7KQm/toVO3dtPmPbwd8//nndWg4bc/AwPvrN6yinTrVhVx3ma0sJTdDS90OQbV04QnFwY2bV6tUrmEYRYdoGkitD3pOVWU6fv66bOGZMydUKlXxYiU9PfNafgsdHC5c/O/bgT0aNq5OJxnp7bTtTC73QeD9EkbH+QH9hwiRRAoXLibkIxEKgXBEssDkqrJPoeOk4blXvvz0RqrW0c5AR0XjD0itA2oX0J4gvCxWtKRhFEX8yVNHhcMyNdhpl/u8Zh3jRZQp60crT00hOng+ffaEdsgPrbkA2kuFfDTM1rhPyngp1i1Vt+szFBVj5jam4PGTh1RFql/vS8oRlgx0SKYqYbsOX1JBbdJM15FCHTuGscWKfdz+Li6u1KJkupaHnEoI1WSpl4beRfmoe5dRCSd2dnYN6jf555+/hZcnTx6t+Vlt6laiYKVuE2oCr9/wOx10KeVp5V1cXFiypa6QUyPa8MMY3l66H1t/9DjI8l7MEm7/TxZycx+NopPWs6RRLxltVeqLe/bsSfzLVBRy87d/TM/TNfRXFJ5QFtBnoJ4F+m88gZBro0ZO3rNnGx0P6Q/j4uzSunXHHt2/oYODhbcsX7GIjk7UxKatT8d5qpft/3t30uVSQae/h729g8nVM/6pk2T2I5hc1U/+ZIrxCjg4OtIjVWaFnSHphUchwe+EGVInlGEg7Qx/rF1x+coFOh6eOnXsiy/qJVooHVepu+DEiSO0ZZb++lOlilV7ft2fOtHoaOzg4Gg8JbVcoqOjDC+Nl2LVLBz2LTAUFWPmNqYwlnoqqHC6u+dkyfDq1csh3/etWKEqNcmpbkjFjA7qxhPQfp70XadP/zt+4nCq8vfvN6Rw4aIXL50bOep/SSf7qlmbXbv/fPb8KXXHU+OAFsF0hc3+559W/LV/FzVpad+hqlnPHv0aNmzKki11hdzBuJDrzwpQIbe847OE2/+ThdzcRwsOfptoBRz13SZUzl1d3VjqCjmfwu9opxFtMtozqaOk1of2hSBfXl0PNB36qFFDBYKODFTTXrd+FR1OqSlt7i3U5t+7bzu1L75q1loYKMRNUrRNqQjSn4qlE3OrmmgyjTbBpdXGKxATHc10G8RRoe8lGT5snJdXfuOJqbNZ+JMbo+Mn7SqnTx+nwyP1VdMOzJKoVvUz+k9tnEuXzm3fsWnsuKE7th+mE0QxMdEJViYq0iNnLpbl6Ip0+l07bnJjCqMaN/qK2iXzF8yoXLl6xQpVLM+HOsUoJqg/0VF/aDSuP1pAPXRUlaOeO+GlueJNRYKqTn//vbto0RIUCtWq1RSGU4/ntwOG0spfvnz+7wN7fpw1saCPr+X+R2PpUMj1rTGqGVje8RNJTiE3+dGcnXV15Gijci50ptGptlRfLWThdI25b9dwjE9TDz21aqnLwNBgoWPLixfPcufOQ+3KI0cOUE8cbU0qFvQ/IOAu9ZdbeAs9iY6O9vDILQynInjmvxMmF0oNluLFS1HXj2HIipWLafpBA4exlLOwqnZKu/ehH0s/1fyN33j16iXD8/sBd+nYSLFIDQp7/cHN8AHp0ErpT0UqONjE0umkzb59OwoW9KXum6R7JvWOxcbF0l7t4ZGrceOvPD3zUcf2y1cvqCFD5ZUWWvRDY59OkvoYtbtTgc64yqX3814s/W7RZm5jCmNph6fOtQsX/qNTKL+v2mrcP5gU9W5TRUbIRyKcjvskepdnno9tW2pEm5uSSiOd+X369DFVwYQ6F50PvHnrWpMvW1Ap/eyzWpSbXzatSb06yYzIVBdy6tEKDX0vdLnS4ujR17cIM78Xm1y65UJu7qNR/tKefvPmVcOpMyrk1IeWK1du6q9gqWamjJv5dk2a71j6TZ//0fGBmsPU8qV+3KnTxgwbMYDSik5L0dmDyVNH0SGLTs8dOvTX/YA7Zcv4WXgLVc7pYELHEGpi0F+Fen9p+vDwsMjIyKTLbdm8HZXmLVvX0Rk36imnbt1CqQ0IC6tKB/M7d25STyI9p2aR0Hdu8Obta+rVokykv/G+v3ZQRzuFI0UhNd/o/Ax9NPpQtPOMGDlw4c+zzC29Tp2GtJceOLCH3i5P8h1p6vGZPGXk3n07qJ5y6/YNOuNPuzftZlWrfkbtkQULZty5e4vWmZonVHo6tu/O0oA6izQqSZ6uSaeVMrcxjacZ+cMkiqRZsydZnpWvb1Hq69izdzu1zc+dP0N1HwqR169fWn4Xnd+7cPEslVh6l3Bmlhgy2li9uo3fvXtDrWwKNWEIxeucuVOpJ5F6USnFNmxcTTMpU1rXS0AHZvrrU0s2JCTY3KJTXcgp1H5ZNCcsPIz+U6mm7q9yZSsw83uxyaVbLuTmPhpVexs2aEodlNR5Skundd65a0u7dl1NdmIkk+4aMjOjzHy7RpvW8keHo+XLNtCn+m35L9T0K12q3PRpC+z1pk6eu2jJXKFXjvJrQP+hwqWL5t5Co6jbZcnS+T17taPjycBvh/n5VT5//kzrtg3+WLM90XKpFhAWHkp/dQrQnDk96AydoTClFDVaza1qq5YdKP76DehKOVivbiM6YUedyoZLiKhD4ObNa9SrRc/p2Dj4fz8Iw6m/n46xGzevoT2HGgv0AYcPN3vxjVc+b+o4v3vvtslrF6gdRPvz4iXzFvz0Ix1CaM/5acFyoVoxfer8Zb8tHDjoaxpOe+y0qfMMl5JlNelUtbWwMQ2oMEyaMOt/3/XesXNLm9Ydzc2qfr3Gjx4FUmT8tHAmdbFRNx9V+jZuWkNH9KRNV4PevQdSU3H8hGHUWqLTstROp5rX6DHfjRs7PdGUdKCtVKnam9evDAd+6jMd9v3YNX/8Rj2J9LJypWoL5i/z8fGl582btaE61w8jB82etYiGm1x0qgu5b6EiPj6FO3RsEhsbm9cz3/SpC4SMs7AXJ2W5kFv4aIMGDqdAnDZjLIUm1Qm6dO7VudPXLA3015CZHsWZvDbwj2kPeS3XdmhBBinUsnX9tm069+jel2UVW+YFOTrLu44uwKRk9aQgpb285SBprVVGo+pY+45N6MBv+LaFKCZNHmm4ujtrOLj22dunsQNm+yYdZaYvEt/PBmmztd+uefnyxbPnT6gToGDBQqluGEEqmL/rOLMJzVvUMTdq1KjJiS7Usk1yOSdX4JgZj1rNmzatMTmKTrYu/uV3ljGOHD2wctUSOrc+eeLslH71bcy4oTeu+5sc1bRpKzplzMA80xEpk3NaZhOWL99oblSO7O4s5XbvTNZJTCui0fAatfSOmCL9Rmfz5m3p3ILJUXTqg2WYrl160X+WKiOGjY8zczWM8Rcxk2/K5Dksa5FzZusBZk7XaHjqi2Q2gHqaGVgjkX6CztXF1fAdLWuR9JYckAgFnrl6AG6GBlaJjvnU1mEAGQw/zACfwEny9B0d82UKlFFINyn7HW3dV2tQ/EAvXb/pl25039FGJRLSCWf+FzXN3OmHx08ngaTh570gHenuPapNyekaAADbwZn/0r/Zi354/LwX6Em0HHCoRUI64jgzX9K2cNEPA9CTZEjy6IuEdMSn7GZoAAY29k0/gAQQkQAAZpmOSDslp7aNb9fAJ8kVvFx6VyAq7WUKCd7oF6yTTM4rlKZb2qa7KO1dOK1awwB0HdPMObvkWht2jpw6DkUU0kdctNbeycy5a5NDy9dyjQpH+QOdmEhttS+zMYkpXtk5MjQFP4UKYEHo27iCpUz/LKDpiCxcLodLDsX2nwMZ2LYt8wLc88hze6fgR0czh1+tnI6u8l2LgxhA2vy1MkihYLVaeZocy1n4Hs3OJU/fPY8pXydniao5GNiY62fe3jwV6l3UvklPbyZVW356HBkcV66ee/GKqblzHdi4hzfDLh1+K1fKuo/1MTcNZ/mrhjuXPnn1KE6j5rUiXibJi3cJHC/eRYGiLlqmYAo58yru8FVv6eajYPuiJ2+exFLPudkreS1uSd0OYL50WS563Kdu9sLxafwhUWElklES0mmaT36iFE2WXMkr6um+bjKZ7tc9c+RWdBzhY2mGyfk2dnRIdES03NS7TXzFQfd1cDNzNZ6c05cfo/UwXZg4/XSW8pnjOC1vriB+uhB/+AOZnGzLli1urm5NmjaxMB/9kjlzFw8K62X2vR82SNL5y7jEvzfExW8kC8syveWNZ27hT2BE4+LGHF0cmfWIDo2OiJSbHMVZ/h6OsEWNpzfaLJy+cFj40/Omnn9crtbEzp9gyiRLT7QOH0abmsb4T8nr/pmcz/6/90eER3To2J72ItO7mPFaevJLAAAQAElEQVTnNV1W4wd/XCszi0v8NqG8JtrTk5Q66uyzsIMbVinBQj98+KRzS/hH4Sxc1WvnzLJls2OfkqwzlY45HB1tsqkdq32tcJLnyvfp7Qjicszm6Ci5U0qSoGJvmV2sR16U4VTCpeOWqNXqRD8WCmBdVCqVUqlkkFqp/3FuW4CIBGuHiEwj7P+WICLB2qEMpxG2nSUoXmDtUItMI+z/lqB4gbXDYT6NsO0sQfECa4cynEbYdpageIG1QxlOI2w7S1C8wNqhDKcRtp0lVLzQFwlWDRGZRth2lqB4gbVDGU4jbDtLULzA2qEMpxG2nSUoXmDtcOFaGmH/t4SKFyISrBoO82mEbWcJihdYO5ThNMK2swTFC6wdynAaYdtZguIF1g5lOI2w7SxBVzdYO0RkGmHbWYLiBdYOZTiNsO0sQfECa4cynEbYdpageIG1QxlOI2w7S9AXCdYOEZlG2HZmafW/HS6T4ed9wIohItMI+79ZPM+XK1du+fLl79+/ZwDWJjIyctWqVb6+vo6O1vST6FKDiDRLLpcvWbKEgrJt27Zjx469du0aA7AGd+/enTJlSpMmTWJjYxcvXozOorTgKAIYfMrBgwc3b95MXZMdO3Zs3rw5A5CkI0eOUEGl+mOnTp1atGjBIM0QkSlw+/btLVu2UCmkoKQi6OHhwQAkIC4ujpJx06ZNZcuWpZJZsWJFBukEEZliUVFRFJRUIqmnkopjpUqVGIBIAgMDqSju3buXimLnzp1z587NIF0hIlPv6NGjlJV0MocqlW3atGEAmejEiRMUjm/evKFwpO5yBhkDEZlWAQEBFJR79uwRWt/58uVjABmGdlihTV24cGEqb9WqVWOQkRCR6UOtVgutbyq4lJU1atRgAOnqyZMnlIxbt24V2tReXl4MMh4iMp2dPHmSsvLZs2dUjikrGUCa/ffffxSOjx8/pmREocpkiMgMQaWZapR0wG/fvj2VaR8fHwaQctu2baNwzJs3L4VjzZo1GWQ6RGTGopSkSmWePHmoUlmrVi0GkAwvX76kZKSjbKtWrSgccYgVESIyM5w7d46K+71794TWt52dHQMw5eLFixSOd+7coWSk0oKvV4sOEZl5qGpAQUmVymbNmlFQFi1alAF8sHv37o0bN2bPnp3CsU6dOgykAREpgp07d1JQurq6UjWhfv36DGzY27dvhYt4Gjdu3KVLlyJFijCQEkSkaC5fvkz7xtWrVzt06ECVShcXFwa2hP70lIxXrlwRLuJxcHBgID2ISJFRJUI4pVO7dm3aVUqVKsUgq/vrr78oHKlLmpKxYcOGDCQMESkVtNtQpVImk1FQNmnShEGWExoaKrSpa9WqReFYsmRJBpKHiJSWGzdu0F50+vTpjno5cuRgYP1u3bpFyUh/VqFNTd3QDKwEIlKKwsLCtuhVqVKFgtLPz4+BdTp06BCFo1qtpmRs2rQpA2uDiJQ02sEoKGNiYuiUTsuWLRlYiaioKKFNXblyZQrHcuXKMbBOiEgrcOfOHTqlc/DgQeFmQsb3BKxXr56jo+OcOXNKly7NIHOdP39+4sSJKpXqyJEjhoH379+nZDx8+LDQpnZ3d2dgzRCRVoPqksLNhOisN+1+1AangZUqVeI4ztvbe9WqVTlz5mSQWZ4/fz5w4MCnT59qtdrLly/TkGPHjlE4UicJJSOq/FkGItL6HD9+nILy3bt3b968iYiIYPrfsy1WrBgNZJBZ2rZt+/DhQzo+0XMnJycXFxc6dFE44i70WQwi0loFBga2b99e2EWZ/k6rn3322aJFixhkvEGDBp09e9aw8ekQ9ffff+fJk4dBloMfibVWQ4YMMeyihJ5T19i0adMYZLCpU6devHjReOPLZLI+ffowyIpQixTHX2uePbsXo4nj1Zr4IRzPeGGnoz8Il3CIfkD83+nD2MTPDcN4/uPea5jAwrtMzSTR0hOvjH4ZRktkXMI5fFzb5OH080gwyNRaJZ1t0kUnXT0LU1papYQf3/KKWV6A2VnpyeTMTsnlK+7QrCfuIi5FiEgR7Fvx7MXD6MLlXX1Kusjs438GntPKeJlW9yxhROqe8px+H9P/pXSDeCEshAk+7Jq6iXQDufi/KC88FWaln1b/RPdMa7THymjJH5MnPoW4Dwv6WDi0Mias3oeJuPgFCjPkuATxxSVY20RpyxJPyj6s3se1MlpJw9sNS0w0q8THD/1CE84/fqSJFeD18zfRmoqfisZojQfrF6Hf5rzpYxhLHKOcbg767WMy97XaB1fDAq6H5fZ2aDXAm4HEICIz27oZQSq1pv1Q3NAFEtj2U6DcjusxthADKUFfZKa6dfZdZCjyEUxo971vRIjm2ul3DKQEEZmprp+OcM6uZACmuLkrb/0XwUBKEJGZKipS6+CCbQ6mOTjLY6LQ8SUt+GWMTKWO0f0HMEkVy8dFaxlICSISAMAsRCQAgFmISAAAsxCRAABmISIzFcfMfH0NQPddb933EUFSEJGZSvcNOg4ZCaZptUyrYSApiMjMRRmpxYVvAFYDEQkAYBYiEkAqqA+Gw3evJAYRCSAVnIyTydBVLS2IyExFdQROjn0ATNNqeI0aXdXSgojMVLyW4XQNgBVBz0emS2FCtmxdf+26lQykBH8U24GIlLqOHbqXK1uBZZagoAedunzFMsWUqaP3/72bpVaqVzWNy2XJ+6OkfSkgBYhIqevSuaefX+b9NPPde7dYZrl7N03LSvWqpnG5LHl/lLQvBaQAv12TqVaMC3LJrviqX/7kv4XadG3bdO7Rve/OXVvXrV+5cMHySVNGPnwY6OtbpH27rl82br5y1ZKdu7bs2nFEqYy/n/nmLWtX/b50986jTk5OBw7u3bN3e1BQQKFCRerVbUSzEr7eEx4RvnrNsnNnT4W8Dy5erFSDBk2aNW1FQwztx4Hffl+5UvXefTsu/uX35SsXXbt2xTNP3k6dvq7gV3nCpBFPnz4uUaL04P/9UKJ4KZpYrVbTEs+eO/X69csyZfxat+xQvfrnwnxatWnQq+eA0ND3f6xd7ujoWKVyjf8NGpEzp0fd+pWFCVxcXPbuPm5hCyRnVStVrNbnm04zZyyct2B69uw5Vi7fRHXMPXu3Xb5y4eXL5z4FfZs2bdWyRTuaOOlyzW0irVb78y+zT50+bqe0q1//yzKly48ZN3T7nwfd3XMa/ig02dlzp7dsWXvn7k13d48yZcr36zvY+NN55fNev24XS56/Vj6NCFb1nYGfr5EQ1CIzlUzOpfqMNiVgRET4L4vm/DB8wtF/LtSu1WDO3KmvXr2sW6dRVFTU+fNnDFOePHWsRvUvKB//OXJg9pwpxYqW2Lh+T98+g7Zt37h46Xxhmjlzpty6eW3o0DFrft9WsmSZnxbOvHnzGmVZp4498uTxPHbkIuWvkLmLl8z7ukc/WmLpMuVXrFy08OdZo0ZOPvj3GXs7e1oZYW70hGbeulXHjRv21q5Vn0L83xNHDKtNCSKTyXbtPPLH6u3Xb/iv+eM3Gn5g/2l6/GHEBMv5mKJVXbt+JTWBhw8bT8+XLJ1/4cJ/Q74bNWvmL5SPFHaUZUmXa2ET/bltw959O+gwsGzZekdHJzoGMP1PZhuv2737d8aMHVKhQhVat+8Gj3zw4N7sOZONl5L8fGS6s3m8FmfzJAYRmam0ap5Pw1UdKpWK0qpUqbJUzWnc6CtqAQQE3C1cuGi+fN4Ui8I07969vXXrer16jen5/v27ypWrMHTI6Bw53CtWqNLr6wG7dm0NCQmmUVevXa5Vq36VytVz587T75vBSxavyZkzl8mFUgWK3ktLrFOrQWRkZIsW7UqVLKNQKOjttHRah9jY2IOH9lHbs0XzttncsjVt0rJ+vS/XrlthmIOXV/5uXXu7urhS9Ypqkffu3WYpkZxVFep9NA3FZckSpen5hAkz585dSmtO1V6qPxYvVvL8hTNJZ25hE9GHqvVFvTq1G9CH6tqll5Ozc9K337ju7+DgQJ+Owrpa1c/mz/21c+eeLLU4Djc5kRxEpJUpod//iaurGz1SvZIeGzZocvLUUY1GdwuEEyePUnv285p1qJ144+ZViiTDe6myQwOvXb9Cz8uW9dv65/pfly08c+YEJS8liKdnXpNLzJ/fR3ji7OJCj76F4n++0dHBkd4YFxdHkUePxgvyK18pMDAgNCxUeFmsWEnDKFrtyMiU/YJV8le1WNGPC2I8v2PH5h4921Kbl/7fuXvrvT74jFnYRLQxqTejdOlyhlG1vqifdIllyvrFxMRQA5yqnE+fPcmWLTslMkstnmeoQ0oNrou0MiZvFNSgfpM/1q6gfjeqRp06deyLL+pRLY92XQoUah4KLUQDoYpEjeU9e7YdPXaQ0sfF2aV16449un9D70o680RNy0Qv2YeYHjykT6LhIcHvqP5lbp2TL/mramdvLzyhmBs9dggF+Dd9/+fnV5kqsElXj1Cym9tEEZERVEF2cvpYc6T4SzoHaqFTQ/7EiSPLVyxa+utPlSpW7fl1f+qRZJBVICIzla4llQFNKW/vAtTcPn36ONXX/K9eop2WBlIDkLojGzVsRq1U44nz5fWmRzdXN2oeUvvxxo2r1Ehft36Vi4trh/bdWMrl9NA1e4cPG0cNauPhuXN7svSQilWlLsI7d27Om7uUMksYQjmeyyN3osksbCInRyem79kwDAwJMf0L19S+pv/UN3rp0rntOzaNHTd0x/bDLFVkCk6uQFNbWhCRmS5j+jbopM2+fTsKFvR1c8tGfWrCwMKFi9HpYEPTj3b4Fy+eUY8eNYGPHDlAnYaUEdSMpf/Uq0ixwlLF26uAvb76ZlgQ1cL0VTAnlmapW1U6gU6PhkykJjP9L+RTOOmU5jYR1Xzp8eHDB4YpT5/5N+nb/f0vxcbFUkR6eORq3PgrT898Q4f1e/nqRdI4Tg7qqsYXEKUGfZGZStfZlDH3TK1TpyHtmQcO7Klbt5FcHn/r6m/6/I+qlvv/3k0Nz+vX/adOGzNsxABqXSrkij/WLp88dRTVy4KD3x069Nf9gDtly/gxfYWUTvicOnX8yZNHyVw0RSG1Lun8DC2CZk7nskeMHEgnvi2/i1I1V67cFy+eveJ/Ua1Wm5ssdavqU9CXWuJbtq4LCw97/PjhosVzqQuCtk/S5ZrbRDTlZzVqHTr814WLZynuqasxPDws6epRV+bkKSPpxPf79yG3bt/YsXMzZaVnnryGpdA8GVgzRGQW4ZXPm85jUPWqft3GhoFU51q+bMO1a1dat21IsUXnSaZPW0B7r7Oz89TJc9++fU09dG3bN968de2A/kObf9WG3lK92ucUQBMmjThy9GDyl96pY48fRkzcuHlN85Z1fv5lNjVUhw8f/8l3de3Sm/pPJ0wcHh0TbW6a1K0qnV8eN3b6rdvXW7aqN3b89337DKIT8bdv3/i6V7tEyzW3iWiyr3v0K1u2wshR/+veo/WjR0Ht2nahgQqF0nhBUCAAYAAAEABJREFU1N5v1rT14iXz6O3fD+tHfZc/LVgu9JMKS5k1exIDa4ZLxzPVirH6S8f7p+DScRALne96/fplgQI+wsvNW9Zu2PD73j3HWYbZt/xJeLCq30xfBpKBWmSmUthxciX6460DZWK/AV2379hMPZtHjx2i8+kt9N/PyTgyOU7XSA5O12QqdRyvUaHanljzFnXMjRo1avLnNeswMfT8ul9oaMihQ/tWrFyUK1ee1q060ll1lpFwv0gJQkSC+DZu3GtulKODIxPPkO9GscwkY7jruNQgIkF8ri6uDIiW4TvaUoOIzFRyBZOhLxLM0P92DQNJQURmKo2aadEXCWbo7/TDQFIQkQAAZiEiAQDMQkRmKrmSyRTobQKwGojITKVRMa0avU1gGscy5EZQkBaISACp4PU3OgFJQUQCAJiFiMxUcgXDd7TBHCobSjsUD2lBRGYqOwemMn9vRLBxapVaYYeuamnB2dVM5VXUKSokY+6pC9YvMkTjVcyZgZQgIjNV3fZ5tDz/3/5nDCChMweeU9mo1z59fvAH0gtuqSuC30YHuOdWfNnHhwHoHVz7+O3TuAGzizCQGESkOH6f/CAmgpfJmUaduHue0134oftd1SR/Gd7we6uJRsW/JX6KhGPjx8QPNx4rTB//PMnYBPM3OZbjGc9ZmCDB/E2um36Y5RUQBlteQ+NpmLnrZozWxtzHNKyR8Zqbm8jSTD4skH1qGqY7g8dptVpHJ67XlMIMpAcRKZrgN9F3LoSroxNHJM/T7sczE/up2T1Xn1WcIQyNJ+P1szM5EyFwWAokWoFPJUmC8SYn5oOCHtFK+Pj4mJ8sOQv91JokGx8/O8sz5D6EO295Vsk5OW1nzxer4eqeU8zbYoIFiEgQ0+LFi52dnXv1yti7eQOkGi76ATGp1Wrh9wIBpAmlE8SEiASJQ+kEMalUKqVSyQCkChEJYkItEiQOpRPEhIgEiUPpBDEhIkHiUDpBTOiLBIlDRIKYUIsEiUPpBDEhIkHiUDpBTIhIkDiUThCTRqNBRIKUoXSCmOh0DSISpAylE8SEhjZIHEoniAkRCRKH0gliQkSCxKF0gphw6ThIHCISxIRaJEgcSieICREJEofSCWJCRILEoXSCmBCRIHEonSAmnK4BiUNEgphQiwSJQ+kEMfn6+qIWCVImYwDiCQgI0Gg0DECqEJEgJmplU1ubAUgVIhLEhIgEiUNfJIgJEQkSh4gEMSEiQeIQkSAmRCRIHCISxISIBIlDRIKYEJEgcYhIEBMiEiQOEQliQkSCxCEiQUyISJA4RCSICREJEoeIBDEplUpEJEgZIhLEJJfLEZEgZYhIEBMa2iBxiEgQEyISJA4RCWJCRILEcTzPM4DM1aBBAwpHmUz2/v17R0dHe3t7ek79krt372YAUoJaJIjA3d09MDBQeB4XF0ePWq22ZcuWDEBicEtdEEG7du2cnZ2Nh3h6enbp0oUBSAwiEkTQoUOH/PnzGw8pW7Zs0aJFGYDEICJBHFRndHJyEp57eHh069aNAUgPIhLE0bRpU19fX+F5yZIlqRbJAKQHEQmioZpjtmzZ3NzcunbtygAkCRf9iO/mueDL/4TGRGrjYk2M5Tj28U/EMcabGm5EJqOzw5+Yj9FsTLzUD6FpOXOLEOZG7zFXdD7MkNc/NTkqnlar4WhmMpnJ9TQ9hw8TmBhnPIG50XoyjmnNrb3RG5NsGbMzNTlDYTMmnVhhxzu5KirWcytd3Z2BtCEiRXbh8LuLh0Ny5LHL6WXH8fKkE/D6XZ6lKy3jZMbz5Cmm+IQL1Q0yFZ7JI8zQZJ4kGMjr2zEpXYRhrSyloD7jzc/D/OiEY1K7BYRZxW/GJMNlmuBncSGv4irUy1GtcU4GEobrIsW0d8WzpwHR3cYVYWCTNswMeBkU3XKANwOpQl+kaN6+iH5yL7rbWOSj7eo6psizgJiXj6IZSBUiUjT/bn3j7CpnYNucs8lO7XzNQKoQkaIJD9M4ZVMysG1O2ewjw3E+QLrQFykaVTRT22PfsHXqWG1slJaBVCEiAcTEyTi5gmMgVYhIADFxvOnrWEEiEJGi4TiLF+6BbdBdmIxrkyUMESka7BqgI+fkchwqpQsRCSAmXsOr1ThUShciUjS6hrYM1Qdbh/4WiUNEiolDS9vm4UgpcYhI0VA8apGQNo/X0n+UA+lCRAKISSbnZHJ8yU26EJEAYtJoeI0aF0ZKFyJSNJyMoQ8KZPh2jbQhIkVDnVDogwKeCgLKgYShE0Q0HMezDL4XWmBgQN36la9f96fnkyaPHD7iW5OTLfx5Vq8+HZjNs7CJMhKu+ZE01CJFw/Mc07BMU6tWfZUqjqXBlKmjq1Sp0bRJS5ZFpX0TpQKdzsZ3tKUMEWkr6tdrzNLm7t1bFJEs60r7JkolVCMlDBEpGk5m/MN/nzZ4SB9HB8c5sxcbhowZNzQ09P3SxWuCgh7s2bvt8pULL18+9yno27Rpq5Yt2iV6O7UiIyLC58/7lZ5HRUXNmDn+ypULhQoVadk8wZT//Xfy6LGD165fCQsLLVmiTPfufSv4Vabh1GCnx7nzpv267Ke9u4/T89On//1j7fJHj4OyZctepEjxIYNH5cnjScNbtq7fo1vfE6eOXrt2Zfeuo26ubuY+UXhE+Oo1y86dPRXyPrh4sVINGjRp1rSV8LnoceaMhcJkBw/umzVn8l97Tzg5OY2bMEypUBYsWGjzlrVarda3UJEfRkwsUqQYTaZWq1f9vvTsuVOvX78sU8avdcsO1at/LszBeJXateuyf/+uXTuOKJXx9zOmWdEbd+88OnvOZMMmOnvu9JYta+/cvenu7lGmTPl+fQfnzOkhbLoFC3/0978YHh5Gm7pJk5atWrZn+j6NPt90onWet2B6fu+CPy34jSUPnbVDS1vK0BcpmpS2sOrWbnjp8vnIyEjhZUxMzMWLZxvU+5KeL1k6/8KF/4Z8N2rWzF8oH3/+ZTbt4RZmNW/+tKdPH8+b++u0KfOCHj6gWDHMk6IzNjZ29KgpP85YWKCAz7jx3wcHv6NRB/brZvjDiAlCPl68dG7i5B8aNWq2dfP+SRNmvXr1YuEvs4SZUPTs27+TQnPunCVOjk4WVmPOnCm3bl4bOnTMmt+3lSxZ5qeFM2/evMYsUsgVV/wvCuvzx5rt7jk9xk8cptHoOix+WTRn2/aNrVt13Lhhb+1a9SdNGfnviSNJV6lh/SYUc+fPnzHM8+SpYzWqf0H5axhy7/6dMWOHVKhQhVbsu8EjHzy4R+kpjBo99rvnz59OmzqfPjg1zGlT375zU1gEPa5dv7Jjh+7ffvs9Szb9peMMJAu1SNHIFSn75lnt2g0WLZl38tTRLxs3p5enTh+nalSdOg3p+YQJM6OiIvN65qPnVOk7cGDP+QtnqleraXI+b9++OXb88KiRk0qVLEMv+/f77sx/J4RRDg4OK5dvdnR0pIohvaRa5O49267f8KfESTST31f/WuuLeu3adqHnNPHAb4eN+GHgnbu3ShQvxXGcm1u2wYNGsE+5eu1yp449qlSuTs/7fTOYPmA2t+yffFdcXGz3bn1pKfnyevXqOaD/gG50PooS9uChfV0692zRvC1NQx2mN25cXbtuhbDmiVYpXz5visWaNWvT83fv3t66dX3SxFnGi7hx3Z82RbeuvWUyGVWN6UMFBgUwfdWSlvX7yi2FChWml1279Dp3/jRVpWf9+DOnrwrSZ2nfritLCTku+pE2RKRoNOqUffOMGnp+5SvRvi1E5OnTxytVrOrurv8VZp7fsWMz7a5PnjwSJs6b18vcfF68eEaPBQv6GoYUL17q/v07wnOK2pWrFvtfvUTZIQx5/z4k6UwCA+8b5yY1k+nxzp2blCaGl59Utqzf1j/XU19B+XIVqZezeLGSyXkXdQ4oFPHl1turAD1SY18ul8fFxVWp/LGrlLbV3wf2hIaFZnPLlmiVGjZo8ue2DVQjpnedOHmUDgmf16xjvIgyZf2oQk3t/cqVqtWoUcvbK7/Q2xAUFEDRKeSjoFjRkkeOHjB+yVJIo+U1uNOPhKGhbU2ozkgtRNp7VSrVf2dPClVIqkuOHjvkiv+Fb/r+b8/uY8eOXKS+MwszCQ17T4/GTWDq4hSevHr1csj3fWnmE8b9eOjAf4cPnjU5h4iICGqM29s7GIYIrVSKV+GlnZ0dS4ZRIydTPfTCxf+oh7FN24ZUM6X+xE++y8FouRRY9BgZSWsUzvTdtdRnKvyfOXsSDQnR9xIkWqUG+rY2dd3S81Onjn3xRT1D5gqKFS1BXRYeOXMtX7Goe4/WVEGmOinTVzkdPmwrwwePjo4yvLSzt2eQtaAWKaaUtq8oE6nHjdrFtMPrWtm1dRFJHWdUfZs3dylVKoXJKC9yeeQ2NxOhMRsTG2MYYoi24/8eproYdURSxYqZqT+yD8EUE/Px158j9XPI6e7BUoLO5FBjlpqrFEBUO163fpWLi2uH9t0STabRJrg2igLR8JyOFvRIYZ3TIxc9GT5snJdXfuOJc+f2TLpcb+8ChQsXpWp4sWIlqb5MaZh0mmpVP6P/1JC/dOnc9h2bxo4bumP7YWdnZ+NPzfQfnJKUpYFCIVPaoaEtXYhIMaW0fUVtRspBqkjGxsbU/Ky2UHejhio9GjLx4cNA+l/Ip7C5mXjquywplYSGLdUZ6dxL9uw56DmdxXZ1dRPykRhOdyRCdS56r/GpFeG5b+GiLNmoCXzkyAHqNKTApRY3/Q8IuHtP3963U9q9D/2YzobeA8GDwPv0kYXe0nv3buuW61uEWtz2+hqc0CImISHBPM8bn4QxVrdOo337dlBvA/VRVqxQJdFYf/9LsXGxFJEeHrkaN/6KttjQYf1evnpBrXUK5fsBd4sWKS5Mefv2DZ9ChVkaqNVaVRwa2tKFhrZo5MrU9NPTOY1r1y5T1UZoZROfgr6UWVu2rgsLD3v8+OGixXPppAHtz+bmkCtXbmqJr1mzjKKH2svTZ4zjPlx14utblNqSe/ZupwbvufNnLl8+T0n0+vVLpqup2dMb6Rw6nVCmsXTimM4Xbd++iRZKQ5b+uoCCxhAcyUHnpulEx+Spoyis6aT5oUN/3Q+4U7aMH42icy9ULw4M1J0hofimBRm/kUKNqtK0XPpPJ2TodEq5shUoCnt+3Z9e0ukUqghTuI8YOXDhz7PMLZ22Hm0iOq9Vt24j6pFMNPbGzauTp4zcu28H1aNv3b6xY+dmykrPPHmrVv2MTvUsWDCDTkzROq/6fSlFZMf23RlkXahFikajSk0/PTWuF/z0IwUW1SKFIZQR48ZOp7hp2aoeNTPHjZn2LvjthIkjvu7VbtIE0xkxZvTUhQtn9hvQlaqQdPKHqnJCDNWv1/jRo0AKmp8WzqScpb7CzVvWbty0Jjw8bNj3Y7t26b16zTI6V75p475GjZq9eft6y5/rFi+dTytQuVJ16gllKUGN1qmT5y5aMpc6EJnuJGMW9i0AAAw2SURBVEzhAf2HNvmyBT1v1bIDZT2tnkajqVe3UbcuvWfNmcx/uP2wb6EiPj6FO3RsQvlOJ/GnT10gZBydHC9cuNjGzWso2Z2dXUqXKjd8+HhzS/fK500V4bv3bn83eGTSsdTYp3BcvGQebWrq06hXt/FPC5YL/ZXTp85f9tvCgYO+puF0RJk2dR7Vf1kayOQ4oy1pHI8bX4tkxdggl+yKr/rnZ5BsxhfAZw37lj8JD1b1m+nLQJJQiwQAMAsRKRq5gimy+qnMMeOG3tDfZyippk1bfTtgKLN5ciXOaEsaIlI0GjVTZ/VTmaNHTVGrVCZHGV9WmXxTJs9hWYtGhTPakoaIhAwkfLMFwHohIgHExHE8mtlShogUjUzO5HLsHbaOZxzuFylliEjRaDW6X79jYNt0l+0jIiUMESka2jdwL1XA/SIlDhEpGp5nuGwfZBwnw48FSxgiUjTUFynDN89snpbHj8RKGiJSNNQXqcW9VAGkDREJAGAWIlI0+p++Qy3S5sl4FAMpQ0SKxt6RMTkDGyfnOHsn3LZVuvC3EU1OL/uIYBUD2xYWEpvTS8lAqhCRomnaM58qjn98L5yBrXoeGBEXw5r18mYgVYhIMXUcnv/fLa9unn3LwPbcPv/uyIaX7Yd4MZAw3HVcZO/fxm2Z+5hO3dg5ylRxn7hMktN17POWfxVMJuO0Wl7GcVozf1ndTPSjzE1jmED35R+eS7o8YRHxEyQpQhz7+BaaIOkSLM//41j99/LMfVrjpSRntsI6m15h4Y2cfp5JVlfY5pyp9dBf8s1rTX03ht5Ff1OtmS+YKpRaVSyj9ekwrIB77mT9oC6IBREpCWf2vX7xMDY26hN/C+H7vJa/r0Z7Jk0gPFqYQDczGW9ymo/v1aeUiYwzniBJdnBGv+zImfqVR8NALv7XZTnj3yk0pKrw7cxP5Twz8UZTnz1+s3D6GNSaeCOnb1CZeKP51dBfk8CZzEF6FwWoue/gOzjJPAvZf9YsTb8uC5kDEQliWrJkiaOjY+/evRmAJOGiHxCTWq0WflkQQJpQOkFMiEiQOJROEJNKpVIqcVUgSBciEsSEWiRIHEoniAkRCRKH0gliQkSCxKF0gpjQFwkSh4gEMaEWCRKH0gliQkSCxKF0gpgQkSBxKJ0gJkQkSBxKJ4gJEQkSh9IJYkJEgsShdIKYEJEgcSidICZEJEgcSieICZeOg8QhIkFMqEWCxKF0gpgQkSBxKJ0gJkQkSBxKJ4gJfZEgcYhIEBNqkSBxKJ0gJkQkSBxKJ4jJwcEBDW2QMhkDEE9ERAR+yR2kDBEJYqJWNrW1GYBUISJBTIhIkDj0RYKYEJEgcYhIEBMiEiQOEQliQkSCxCEiQUyISJA4RCSICREJEoeIBDEhIkHiEJEgJqVSqVKpGIBUISJBTKhFgsQhIkFMiEiQOEQkiAkRCRKHiAQxISJB4hCRICZEJEgcIhLEhIgEiUNEgpgQkSBxHG5oCqJo2bIlPb57987R0ZGCkuM4e3v7nTt3MgApQS0SRNCmTZtnz54Jz2NiYuhRo9E0bNiQAUgMbqkLIqhXr55MlqDs5c2bt1OnTgxAYhCRIIIePXr4+PgYXmq1Wl9f34oVKzIAiUFEggjc3NyaNWtmqEi6u7t37tyZAUgPIhLEQZlYoEAB9qEKWbNmTQYgPYhIEIednV3Hjh3p0dXVtUOHDgxAknDRD3xa8KuY6ydD3zyNjYniNRpeFfexzMhkHGO8Vqt7otXyxo/xE3Cclk8wRHgXz3hey8JCwxjHsmfPJryL134sjrqXvL6EalnCxdE744utbtlG66m05xRy3s5JnsvLvuzn2XJ6OjCAtEFEgiXbFz958yROrab8YnKFXK6QcRR2GqMyw3G6/5SR9EhlyfgxfgJ9jBkPEd7FmNE0wruEhw8oDXkhAo3f+GFiU8VWpqB101KIa1VaWkm5gnnks28/ND8DSC1EJJi2cfaj4FcqhYMsW27nvMU9mBV6fu9d+IuIuDhtzjzKLqMKMoCUQ0RCYucOvb148L29k8Knal6Fwuq/XKDRaALPvoiLVlVplKNq45wMICUQkZDAtp+fvH4S61U+TzYPJ5aFhL6JfHrttWcB+7bfod0NKYAz2vDRqT1v3jyPK1W/UBbLR5Itl3Pp+oVeP4s7sfMtA0g21CIh3pYFj4Jfq0vW9mFZ2u3jQTly23UaXoABJANqkaDzz8aXwS+yfj6SknUKhbxWHVr3kgEkAyISmFqtvnMhomQ9H2YbStbxuXc5IjoijgF8CiIS2OoJj5zd7ZgtcfFwXDfjCQP4FESkrbt6Kjg2hi9U2YvZEp+KnqpY/urxYAZgESLS1l04GOKYQ7pVyO1758xdlCE3AXLK4XD+8HsGYBEi0tbFRGgLV7StKqSgUOW8MZFaBmARItKmHV7/glPImZzZJoUdd2j9CwZgHn67xqY9D4yxd8jAgLxwed9/F3a+eBWQN08Rv7INvqjRidPfwGLSzMaN6/eLjHp/6OhKezvH4kWrt2wyzM1N903w2NioDdsmBgRepLfUqNKGZSSlk/LFwxgGYB5qkTYtOlLjkC2jOiIvXz24Zec073zFxw7b2aThtyfObN69/ydhlFyuPH5qPcfJpo45NPK7rUGPrh48tkIYtXXXjLfvnvTvufjrzrNfvg68c+80yzCOrvbR4WhrgyWISJum1TBHN3uWMc5f2u1bsEKb5iNdXdyL+lamauPpc3+GR8SfRPZw925Qu5ejoytVHosXqf702R0aGBr25uqNf+p+3r1g/jJurjm/avw/pSID7/no6GaX4MZuAEkgIm0azzN7hwypRWq12qDH14oVrWYYQinJ89qgh/7CS2+vkoZRjo5uMbER9CQ4RPfLsXlyFzKMym80Wbqzc7bH92/BMvRF2jSecRnUzlSr4zQa1YF/ltF/4+HhkYZLEbmk74qMCqVHe7uPN9Gws3NkGUbGcQwRCRYhIm2ajONVcbFUjWPpzc7OgZKukl/TcqXrGQ/P6W7pAiNnp2z0GKf6eAolJjaSZZjoyBhTQQ3wESLSpskVXHSoimXMZZH58haLjgkv4ltJeKlWq96FPMueLY+Ft+TIno8eHz6+JrSv6S33H5x3ds7BMkZ0aKzcVi94gmRCX6RNc3CRxYTFsozRtOG3N27/e+7SHl2/5CP/9VvH/bZ6EDXALbwle7bcPgXKHzy6/PWbRypV7IY/J8T/yk3GiAmNtXfCLgCWoHzYNM8CDqpoNcsYhQr6ff/tWjo/M3n2l7+tGRwdE9Gr61yl8hMn0Du3nVTAu/TCX3uMm17XydGtasUWLMNOqcRGqfIUzKgT+pA14Ja6tm7x9wFlGhViNunGoaB+swvZ2aGxDWahFmnrlPZc4IXnzPYEXnyusGfIR7AMp2tsXZVG2f/7K8TCBNt2z/K/cdjkKI1GLZebLkKd2kwsU7I2SydHT/xx9ORak6Mc7V2i9ddUJtWt/fQSxWowM6KCY6s1y8YALEJDG9hvowPt3ex9KniaHBsZ+T42LsrkqDhVrJ2ZvkUXZ3c7u3T7Ykx0dDidHDc5Ki4uxtyCLKzDwysvot/HfDunCAOwCBEJLCw4Zu30p2Ua2lCPJPVCdh7lldMzA69Lh6wBfZHA3NwdfMs63Tn+iNmG28cfFiztgHyE5EBEgk7TXvlcc8junMj6KXn35CPXHIrmfb0ZQDKgoQ0fHdn86t7l8JJ1s2yLm+qPRSu4NOiUhwEkD2qR8FH9Tnmy51beOhoUHZHVbjQbHRZz69jDHLmUyEdIEdQiIbETO19dPxlu56IsWiOLtEYDzjyLjYor85lb7ba5GUBKICLBtLXTHoYFq5WO8uxernl8M+pGEhnqdVBIyNMIVYzaNbvi64k+DCDlEJFgVlRo3K7fXr5/HcdrmUzJyZVyuUImkyfqnOHYx3suyvTPeVOjjJ8bJjZ5s8qkUxoN15rpHOJ143mO41UatUajVWu1anrFsudStujr5eKOr0hAKiEi4dOe3Iu8dTYs+JUqLkYXPbExH8uMjGNa/uNznn286YRhFEUVxZs24fD4O/jwHK8PRMM0urvcfniXQHhpvCBhLA2XyZhWH7NCrCrtOYWSs3Pg3PPalajsUrCEKwNIG0QkAIBZaIAAAJiFiAQAMAsRCQBgFiISAMAsRCQAgFmISAAAs/4PAAD//ziOSz0AAAAGSURBVAMAIlimiivGAoIAAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x15a716ef0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc30bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
